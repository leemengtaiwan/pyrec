{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb8ea260-f3bd-43e0-8c73-1728083047a8",
   "metadata": {},
   "source": [
    "- https://datawhalechina.github.io/fun-rec/#/ch03/ch3.1/markdown/ch3.1.3\n",
    "- https://tianchi.aliyun.com/notebook-ai/detail?spm=5176.12586969.1002.9.410521d8XAzkkw&postId=144452"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014ba55c-f57e-4ab3-8472-291707cf4ed1",
   "metadata": {},
   "source": [
    "# 多路召回\n",
    "所谓的“多路召回”策略，就是指采用不同的策略、特征或简单模型，分别召回一部分候选集，然后把候选集混合在一起供后续排序模型使用，可以明显的看出，“多路召回策略”是在“计算速度”和“召回率”之间进行权衡的结果。其中，各种简单策略保证候选集的快速召回，从不同角度设计的策略保证召回率接近理想的状态，不至于损伤排序效果。如下图是多路召回的一个示意图，在多路召回中，每个策略之间毫不相关，所以一般可以写并发多线程同时进行，这样可以更加高效。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e739027-e187-40c6-afcd-8b8dc5e5d348",
   "metadata": {},
   "source": [
    "![ss](images/recall.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53058cc",
   "metadata": {},
   "source": [
    "# 导包"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ccb777f",
   "metadata": {},
   "source": [
    "faiss\n",
    "```\n",
    "brew install libomp\n",
    "pip install faiss-cpu\n",
    "pip install deepctr[cpu]\n",
    "\n",
    "# gpu\n",
    "conda install -c conda-forge faiss-gpu\n",
    "pip install deepctr[gpu]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f24b5827",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np\n",
    "from tqdm import tqdm  \n",
    "from collections import defaultdict  \n",
    "import os, math, warnings, math, pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "import collections\n",
    "import random\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cc94429",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4671f698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.7.2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import faiss\n",
    "faiss.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57047e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from tensorflow.python.keras import backend as K\n",
    "# from tensorflow.python.keras.models import Model\n",
    "# from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "# tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72d93941-d1f3-453b-8c0a-7b866721e800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import deepctr\n",
    "# from deepctr.feature_column import SparseFeat, VarLenSparseFeat\n",
    "\n",
    "# from deepmatch.models import *\n",
    "# from deepmatch.utils import sampledsoftmaxloss\n",
    "\n",
    "# deepctr.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ae7e714-2300-4b5d-9e3a-d55bf44b39de",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8fadb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './data/'\n",
    "save_path = './tmp_results/'\n",
    "\n",
    "# 做召回评估的一个标志, 如果不进行评估就是直接使用全量数据进行召回\n",
    "metric_recall = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e929e4a",
   "metadata": {},
   "source": [
    "# 读取数据"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380be426",
   "metadata": {},
   "source": [
    "在一般的推荐系统比赛中读取数据部分主要分为三种模式， 不同的模式对应的不同的数据集：\n",
    "\n",
    "1. Debug模式： 这个的目的是帮助我们基于数据先搭建一个简易的baseline并跑通， 保证写的baseline代码没有什么问题。 由于推荐比赛的数据往往非常巨大， 如果一上来直接采用全部的数据进行分析，搭建baseline框架， 往往会带来时间和设备上的损耗， **所以这时候我们往往需要从海量数据的训练集中随机抽取一部分样本来进行调试(train_click_log_sample)**， 先跑通一个baseline。\n",
    "2. 线下验证模式： 这个的目的是帮助我们在线下基于已有的训练集数据， 来选择好合适的模型和一些超参数。 **所以我们这一块只需要加载整个训练集(train_click_log)**， 然后把整个训练集再分成训练集和验证集。 训练集是模型的训练数据， 验证集部分帮助我们调整模型的参数和其他的一些超参数。\n",
    "3. 线上模式： 我们用debug模式搭建起一个推荐系统比赛的baseline， 用线下验证模式选择好了模型和一些超参数， 这一部分就是真正的对于给定的测试集进行预测， 提交到线上， 所以这一块使用的训练数据集是全量的数据集(train_click_log+test_click_log)\n",
    "\n",
    "下面就分别对这三种不同的数据读取模式先建立不同的代导入函数， 方便后面针对不同的模式下导入数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6351da14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug模式： 从训练集中划出一部分数据来调试代码\n",
    "def get_all_click_sample(data_path, sample_nums=100):\n",
    "    \"\"\"\n",
    "        训练集中采样一部分数据调试\n",
    "        data_path: 原数据的存储路径\n",
    "        sample_nums: 采样数目（这里由于机器的内存限制，可以采样用户做）\n",
    "    \"\"\"\n",
    "    all_click = pd.read_csv(data_path + 'train_click_log.csv')\n",
    "    all_user_ids = all_click.user_id.unique()\n",
    "\n",
    "    sample_user_ids = np.random.choice(all_user_ids, size=sample_nums, replace=False) \n",
    "    all_click = all_click[all_click['user_id'].isin(sample_user_ids)]\n",
    "    \n",
    "    all_click = all_click.drop_duplicates((['user_id', 'click_article_id', 'click_timestamp']))\n",
    "    return all_click\n",
    "\n",
    "# 读取点击数据，这里分成线上和线下，如果是为了获取线上提交结果应该讲测试集中的点击数据合并到总的数据中\n",
    "# 如果是为了线下验证模型的有效性或者特征的有效性，可以只使用训练集\n",
    "def get_all_click_df(data_path='./data_raw/', offline=True):\n",
    "    if offline:\n",
    "        all_click = pd.read_csv(data_path + 'train_click_log.csv')\n",
    "    else:\n",
    "        trn_click = pd.read_csv(data_path + 'train_click_log.csv')\n",
    "        tst_click = pd.read_csv(data_path + 'testA_click_log.csv')\n",
    "\n",
    "        all_click = trn_click.append(tst_click)\n",
    "    \n",
    "    all_click = all_click.drop_duplicates((['user_id', 'click_article_id', 'click_timestamp']))\n",
    "    return all_click\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b384063a-928d-4117-989d-88a260110739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59, 9)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = get_all_click_sample(data_path, 10)\n",
    "c.columns = ['u', 'a', 'ts', 'env', 'device', 'os', 'country', 'reg', 'ref']\n",
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f5a9ee9-4362-4cf6-9a5b-7cdfaa54f1ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>u</th>\n",
       "      <th>a</th>\n",
       "      <th>ts</th>\n",
       "      <th>env</th>\n",
       "      <th>device</th>\n",
       "      <th>os</th>\n",
       "      <th>country</th>\n",
       "      <th>reg</th>\n",
       "      <th>ref</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2128</th>\n",
       "      <td>199244</td>\n",
       "      <td>175040</td>\n",
       "      <td>1507040326185</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2129</th>\n",
       "      <td>199244</td>\n",
       "      <td>272143</td>\n",
       "      <td>1507040327192</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2130</th>\n",
       "      <td>199244</td>\n",
       "      <td>199198</td>\n",
       "      <td>1507040333389</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2131</th>\n",
       "      <td>199244</td>\n",
       "      <td>64329</td>\n",
       "      <td>1507040363389</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8856</th>\n",
       "      <td>196791</td>\n",
       "      <td>64329</td>\n",
       "      <td>1507035950133</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           u       a             ts  env  device  os  country  reg  ref\n",
       "2128  199244  175040  1507040326185    4       1  17        1   20    2\n",
       "2129  199244  272143  1507040327192    4       1  17        1   20    2\n",
       "2130  199244  199198  1507040333389    4       1  17        1   20    2\n",
       "2131  199244   64329  1507040363389    4       1  17        1   20    2\n",
       "8856  196791   64329  1507035950133    4       1  17        1    2    2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "206dabf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取文章的基本属性\n",
    "def get_item_info_df(data_path):\n",
    "    item_info_df = pd.read_csv(data_path + 'articles.csv')\n",
    "    \n",
    "    # 为了方便与训练集中的click_article_id拼接，需要把article_id修改成click_article_id\n",
    "    item_info_df = item_info_df.rename(columns={'article_id': 'click_article_id'})\n",
    "    \n",
    "    return item_info_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef3095a8-514b-41bd-b294-015d2d78788e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53, 4)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = get_item_info_df(data_path)\n",
    "a.columns = ['a', 'c', 'ts_created', 'w_cnt']\n",
    "a = a[a.a.isin(c.a)]\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52818a6b-dc42-4230-a420-75f10996e37e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a             53\n",
       "c             29\n",
       "ts_created    53\n",
       "w_cnt         46\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e90ba09f-e29d-44be-8007-065fbe73d8e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>c</th>\n",
       "      <th>ts_created</th>\n",
       "      <th>w_cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20691</th>\n",
       "      <td>20691</td>\n",
       "      <td>9</td>\n",
       "      <td>1507826236000</td>\n",
       "      <td>226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29953</th>\n",
       "      <td>29953</td>\n",
       "      <td>26</td>\n",
       "      <td>1507633764000</td>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39894</th>\n",
       "      <td>39894</td>\n",
       "      <td>66</td>\n",
       "      <td>1508152707000</td>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58193</th>\n",
       "      <td>58193</td>\n",
       "      <td>118</td>\n",
       "      <td>1507052481000</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58565</th>\n",
       "      <td>58565</td>\n",
       "      <td>118</td>\n",
       "      <td>1507631740000</td>\n",
       "      <td>231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           a    c     ts_created  w_cnt\n",
       "20691  20691    9  1507826236000    226\n",
       "29953  29953   26  1507633764000    175\n",
       "39894  39894   66  1508152707000    175\n",
       "58193  58193  118  1507052481000    196\n",
       "58565  58565  118  1507631740000    231"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e7369244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取文章的Embedding数据\n",
    "def get_item_emb_dict(data_path):\n",
    "    item_emb_df = pd.read_csv(data_path + 'articles_emb.csv')\n",
    "    \n",
    "    item_emb_cols = [x for x in item_emb_df.columns if 'emb' in x]\n",
    "    item_emb_np = np.ascontiguousarray(item_emb_df[item_emb_cols])\n",
    "    # 进行归一化\n",
    "    item_emb_np = item_emb_np / np.linalg.norm(item_emb_np, axis=1, keepdims=True)\n",
    "\n",
    "    item_emb_dict = dict(zip(item_emb_df['article_id'], item_emb_np))\n",
    "    \n",
    "    # pickle.dump(item_emb_dict, open(save_path + 'item_content_emb.pkl', 'wb'))\n",
    "    \n",
    "    return item_emb_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a8cb66c-3825-4672-90f5-c6a4f3a6fa7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.91 s, sys: 1.14 s, total: 9.04 s\n",
      "Wall time: 9.05 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "364047"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "a_emb_d = get_item_emb_dict(data_path)\n",
    "# a_emb_d = {a: emb for a, emb in a_emb_d.items() if a in c.a }\n",
    "len(a_emb_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c3c5b9c9-5201-4a86-877f-28780b2f471f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.02118425, -0.12580893, -0.01813001,  0.00668391,  0.10909397,\n",
       "        0.11846624, -0.04404838, -0.07354293, -0.06579412,  0.02170995])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_emb_d[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dff9c446",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_min_scaler = lambda x : (x-np.min(x))/(np.max(x)-np.min(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8428cd56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 337 ms, sys: 23.9 ms, total: 361 ms\n",
      "Wall time: 359 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 采样数据\n",
    "all_click_df = get_all_click_sample(data_path)\n",
    "\n",
    "# # 全量训练集\n",
    "# all_click_df = get_all_click_df(offline=False)\n",
    "\n",
    "# 对时间戳进行归一化,用于在关联规则的时候计算权重\n",
    "all_click_df['click_timestamp'] = all_click_df[['click_timestamp']].apply(max_min_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3682cd32-4ef1-486c-8196-4156e98d585f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>click_article_id</th>\n",
       "      <th>click_timestamp</th>\n",
       "      <th>click_environment</th>\n",
       "      <th>click_deviceGroup</th>\n",
       "      <th>click_os</th>\n",
       "      <th>click_country</th>\n",
       "      <th>click_region</th>\n",
       "      <th>click_referrer_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15493</th>\n",
       "      <td>194453</td>\n",
       "      <td>156624</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15494</th>\n",
       "      <td>194453</td>\n",
       "      <td>272143</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33313</th>\n",
       "      <td>188180</td>\n",
       "      <td>70646</td>\n",
       "      <td>0.007562</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33314</th>\n",
       "      <td>188180</td>\n",
       "      <td>199197</td>\n",
       "      <td>0.007588</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35168</th>\n",
       "      <td>187531</td>\n",
       "      <td>70646</td>\n",
       "      <td>0.008231</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1108881</th>\n",
       "      <td>66952</td>\n",
       "      <td>70986</td>\n",
       "      <td>0.999502</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1108882</th>\n",
       "      <td>66952</td>\n",
       "      <td>156279</td>\n",
       "      <td>0.999528</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1109254</th>\n",
       "      <td>45919</td>\n",
       "      <td>202320</td>\n",
       "      <td>0.999886</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1109255</th>\n",
       "      <td>45919</td>\n",
       "      <td>226563</td>\n",
       "      <td>0.999974</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1109256</th>\n",
       "      <td>45919</td>\n",
       "      <td>50494</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>499 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id  click_article_id  click_timestamp  click_environment  \\\n",
       "15493     194453            156624         0.000000                  4   \n",
       "15494     194453            272143         0.000026                  4   \n",
       "33313     188180             70646         0.007562                  4   \n",
       "33314     188180            199197         0.007588                  4   \n",
       "35168     187531             70646         0.008231                  4   \n",
       "...          ...               ...              ...                ...   \n",
       "1108881    66952             70986         0.999502                  4   \n",
       "1108882    66952            156279         0.999528                  4   \n",
       "1109254    45919            202320         0.999886                  4   \n",
       "1109255    45919            226563         0.999974                  4   \n",
       "1109256    45919             50494         1.000000                  4   \n",
       "\n",
       "         click_deviceGroup  click_os  click_country  click_region  \\\n",
       "15493                    1        17              1            18   \n",
       "15494                    1        17              1            18   \n",
       "33313                    3         2              1             6   \n",
       "33314                    3         2              1             6   \n",
       "35168                    3        20              1            21   \n",
       "...                    ...       ...            ...           ...   \n",
       "1108881                  1        13              1            25   \n",
       "1108882                  1        13              1            25   \n",
       "1109254                  3         2              1            25   \n",
       "1109255                  3         2              1            25   \n",
       "1109256                  3         2              1            25   \n",
       "\n",
       "         click_referrer_type  \n",
       "15493                      2  \n",
       "15494                      2  \n",
       "33313                      2  \n",
       "33314                      2  \n",
       "35168                      2  \n",
       "...                      ...  \n",
       "1108881                    2  \n",
       "1108882                    2  \n",
       "1109254                    1  \n",
       "1109255                    1  \n",
       "1109256                    1  \n",
       "\n",
       "[499 rows x 9 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_click_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dd4d2102-8da0-4f80-9439-0c059e313395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((499, 9), 100)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_click_df.shape, all_click_df.user_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "900b7065",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_info_df = get_item_info_df(data_path)\n",
    "item_emb_dict = get_item_emb_dict(data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e578d89c-29a1-4ca0-b06c-d9bf0b6a55ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>click_article_id</th>\n",
       "      <th>category_id</th>\n",
       "      <th>created_at_ts</th>\n",
       "      <th>words_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1513144419000</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1405341936000</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1408667706000</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1408468313000</td>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1407071171000</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364042</th>\n",
       "      <td>364042</td>\n",
       "      <td>460</td>\n",
       "      <td>1434034118000</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364043</th>\n",
       "      <td>364043</td>\n",
       "      <td>460</td>\n",
       "      <td>1434148472000</td>\n",
       "      <td>463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364044</th>\n",
       "      <td>364044</td>\n",
       "      <td>460</td>\n",
       "      <td>1457974279000</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364045</th>\n",
       "      <td>364045</td>\n",
       "      <td>460</td>\n",
       "      <td>1515964737000</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364046</th>\n",
       "      <td>364046</td>\n",
       "      <td>460</td>\n",
       "      <td>1505811330000</td>\n",
       "      <td>479</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>364047 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        click_article_id  category_id  created_at_ts  words_count\n",
       "0                      0            0  1513144419000          168\n",
       "1                      1            1  1405341936000          189\n",
       "2                      2            1  1408667706000          250\n",
       "3                      3            1  1408468313000          230\n",
       "4                      4            1  1407071171000          162\n",
       "...                  ...          ...            ...          ...\n",
       "364042            364042          460  1434034118000          144\n",
       "364043            364043          460  1434148472000          463\n",
       "364044            364044          460  1457974279000          177\n",
       "364045            364045          460  1515964737000          126\n",
       "364046            364046          460  1505811330000          479\n",
       "\n",
       "[364047 rows x 4 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8ecc0893-41f8-488e-a45a-11c5eaee8c6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_emb_dict[364046].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a743cc",
   "metadata": {},
   "source": [
    "# 工具函数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6312061",
   "metadata": {},
   "source": [
    "## 获取用户-文章-时间函数\n",
    "\n",
    "这个在基于关联规则的用户协同过滤的时候会用到"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5921a94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据点击时间获取用户的点击文章序列   {user1: {item1: time1, item2: time2..}...}\n",
    "def get_user_item_time(click_df):\n",
    "    \n",
    "    click_df = click_df.sort_values('click_timestamp')\n",
    "    \n",
    "    def make_item_time_pair(df):\n",
    "        return list(zip(df['click_article_id'], df['click_timestamp']))\n",
    "    \n",
    "    user_item_time_df = click_df.groupby('user_id')['click_article_id', 'click_timestamp'].apply(lambda x: make_item_time_pair(x))\\\n",
    "                                                            .reset_index().rename(columns={0: 'item_time_list'})\n",
    "    user_item_time_dict = dict(zip(user_item_time_df['user_id'], user_item_time_df['item_time_list']))\n",
    "    \n",
    "    return user_item_time_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6eabb4c8-ac71-41c5-abed-04b169e75b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_it = get_user_item_time(all_click_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "826d01a5-31c7-495c-ac96-5e9ff8fb4d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# u_it[94]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e5f41971-73bb-4c99-a7d9-69d1bbf54e81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(u_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cb9f8067-7f44-426b-9f84-5da3242a76b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>click_article_id</th>\n",
       "      <th>click_timestamp</th>\n",
       "      <th>click_environment</th>\n",
       "      <th>click_deviceGroup</th>\n",
       "      <th>click_os</th>\n",
       "      <th>click_country</th>\n",
       "      <th>click_region</th>\n",
       "      <th>click_referrer_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [user_id, click_article_id, click_timestamp, click_environment, click_deviceGroup, click_os, click_country, click_region, click_referrer_type]\n",
       "Index: []"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_click_df[all_click_df.user_id == 94]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06733b0",
   "metadata": {},
   "source": [
    "## 获取文章-用户-时间函数\n",
    "这个在基于关联规则的文章协同过滤的时候会用到"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "29c330ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据时间获取商品被点击的用户序列  {item1: {user1: time1, user2: time2...}...}\n",
    "# 这里的时间是用户点击当前商品的时间，好像没有直接的关系。\n",
    "def get_item_user_time_dict(click_df):\n",
    "    def make_user_time_pair(df):\n",
    "        return list(zip(df['user_id'], df['click_timestamp']))\n",
    "    \n",
    "    click_df = click_df.sort_values('click_timestamp')\n",
    "    item_user_time_df = click_df.groupby('click_article_id')['user_id', 'click_timestamp'].apply(lambda x: make_user_time_pair(x))\\\n",
    "                                                            .reset_index().rename(columns={0: 'user_time_list'})\n",
    "    \n",
    "    item_user_time_dict = dict(zip(item_user_time_df['click_article_id'], item_user_time_df['user_time_list']))\n",
    "    return item_user_time_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e9a9fab7-a94e-4dc1-a01a-a48c0d09c0a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "345"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i_ut = get_item_user_time_dict(all_click_df)\n",
    "len(i_ut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "077338e4-96c0-4601-b4ab-89993c16d2d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "345"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_click_df.click_article_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7cd5a6e4-2171-4c36-9819-297a2516bf52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>click_article_id</th>\n",
       "      <th>click_timestamp</th>\n",
       "      <th>click_environment</th>\n",
       "      <th>click_deviceGroup</th>\n",
       "      <th>click_os</th>\n",
       "      <th>click_country</th>\n",
       "      <th>click_region</th>\n",
       "      <th>click_referrer_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>986069</th>\n",
       "      <td>65426</td>\n",
       "      <td>2807</td>\n",
       "      <td>0.884929</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587110</th>\n",
       "      <td>63762</td>\n",
       "      <td>7744</td>\n",
       "      <td>0.510525</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485625</th>\n",
       "      <td>79949</td>\n",
       "      <td>8211</td>\n",
       "      <td>0.443996</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999090</th>\n",
       "      <td>65426</td>\n",
       "      <td>10411</td>\n",
       "      <td>0.906929</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510891</th>\n",
       "      <td>76150</td>\n",
       "      <td>19578</td>\n",
       "      <td>0.455511</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841625</th>\n",
       "      <td>115625</td>\n",
       "      <td>20691</td>\n",
       "      <td>0.701149</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861945</th>\n",
       "      <td>66420</td>\n",
       "      <td>20691</td>\n",
       "      <td>0.728492</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869093</th>\n",
       "      <td>63762</td>\n",
       "      <td>20691</td>\n",
       "      <td>0.733860</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629839</th>\n",
       "      <td>157329</td>\n",
       "      <td>29953</td>\n",
       "      <td>0.529404</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648670</th>\n",
       "      <td>165601</td>\n",
       "      <td>29953</td>\n",
       "      <td>0.531474</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  click_article_id  click_timestamp  click_environment  \\\n",
       "986069    65426              2807         0.884929                  2   \n",
       "587110    63762              7744         0.510525                  4   \n",
       "485625    79949              8211         0.443996                  4   \n",
       "999090    65426             10411         0.906929                  2   \n",
       "510891    76150             19578         0.455511                  4   \n",
       "841625   115625             20691         0.701149                  4   \n",
       "861945    66420             20691         0.728492                  4   \n",
       "869093    63762             20691         0.733860                  4   \n",
       "629839   157329             29953         0.529404                  4   \n",
       "648670   165601             29953         0.531474                  4   \n",
       "\n",
       "        click_deviceGroup  click_os  click_country  click_region  \\\n",
       "986069                  3        20              1            13   \n",
       "587110                  1        17              1             2   \n",
       "485625                  3         2              1            10   \n",
       "999090                  3        20              1            13   \n",
       "510891                  3        20              1             4   \n",
       "841625                  1        17              1            25   \n",
       "861945                  1        17             11            28   \n",
       "869093                  1        17              1             2   \n",
       "629839                  1        17              1            25   \n",
       "648670                  1        17              1            21   \n",
       "\n",
       "        click_referrer_type  \n",
       "986069                    1  \n",
       "587110                    1  \n",
       "485625                    5  \n",
       "999090                    2  \n",
       "510891                    2  \n",
       "841625                    2  \n",
       "861945                    2  \n",
       "869093                    2  \n",
       "629839                    1  \n",
       "648670                    5  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_click_df.sort_values(['click_article_id', 'click_timestamp']).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "92144fbd-0147-44d1-b8a3-b691e83f0849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(115625, 0.7011486503295372),\n",
       " (66420, 0.7284916396085593),\n",
       " (63762, 0.7338601690305064)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i_ut[20691]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b88b990-7430-41a3-9c9d-d2be18ec76fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440d1db1-50f3-42a4-a959-969fbc3d45d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6c08418f",
   "metadata": {},
   "source": [
    "## 获取历史和最后一次点击\n",
    "这个在评估召回结果， 特征工程和制作标签转成监督学习测试集的时候回用到"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f715431f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取当前数据的历史点击和最后一次点击\n",
    "def get_hist_and_last_click(all_click):\n",
    "    \n",
    "    all_click = all_click.sort_values(by=['user_id', 'click_timestamp'])\n",
    "    click_last_df = all_click.groupby('user_id').tail(1)\n",
    "\n",
    "    # 如果用户只有一个点击，hist为空了，会导致训练的时候这个用户不可见，此时默认泄露一下\n",
    "    def hist_func(user_df):\n",
    "        if len(user_df) == 1:\n",
    "            print(user_df)\n",
    "            return user_df\n",
    "        else:\n",
    "            return user_df[:-1]\n",
    "\n",
    "    click_hist_df = all_click.groupby('user_id').apply(hist_func).reset_index(drop=True)\n",
    "\n",
    "    return click_hist_df, click_last_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d2827ce1-764e-45b2-a502-ebbe7ffe627b",
   "metadata": {},
   "outputs": [],
   "source": [
    "click_hist_df, click_last_df = get_hist_and_last_click(all_click_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6ac06aa1-4644-4a0d-b655-29de22ddebba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((399, 9), (100, 9), (499, 9))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "click_hist_df.shape, click_last_df.shape, all_click_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "392cfd72-8ba0-4d2a-a16a-6315d619ba2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>click_article_id</th>\n",
       "      <th>click_timestamp</th>\n",
       "      <th>click_environment</th>\n",
       "      <th>click_deviceGroup</th>\n",
       "      <th>click_os</th>\n",
       "      <th>click_country</th>\n",
       "      <th>click_region</th>\n",
       "      <th>click_referrer_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1096659</th>\n",
       "      <td>1863</td>\n",
       "      <td>96877</td>\n",
       "      <td>0.987333</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1033258</th>\n",
       "      <td>7764</td>\n",
       "      <td>206785</td>\n",
       "      <td>0.952268</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026746</th>\n",
       "      <td>8466</td>\n",
       "      <td>202355</td>\n",
       "      <td>0.942660</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022520</th>\n",
       "      <td>9015</td>\n",
       "      <td>165547</td>\n",
       "      <td>0.926944</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003477</th>\n",
       "      <td>11654</td>\n",
       "      <td>214753</td>\n",
       "      <td>0.910707</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36724</th>\n",
       "      <td>187019</td>\n",
       "      <td>272143</td>\n",
       "      <td>0.008807</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880390</th>\n",
       "      <td>187214</td>\n",
       "      <td>159196</td>\n",
       "      <td>0.739727</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653783</th>\n",
       "      <td>187531</td>\n",
       "      <td>208118</td>\n",
       "      <td>0.533928</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004445</th>\n",
       "      <td>188180</td>\n",
       "      <td>202559</td>\n",
       "      <td>0.913877</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1057329</th>\n",
       "      <td>194453</td>\n",
       "      <td>206571</td>\n",
       "      <td>0.981858</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id  click_article_id  click_timestamp  click_environment  \\\n",
       "1096659     1863             96877         0.987333                  4   \n",
       "1033258     7764            206785         0.952268                  4   \n",
       "1026746     8466            202355         0.942660                  4   \n",
       "1022520     9015            165547         0.926944                  4   \n",
       "1003477    11654            214753         0.910707                  4   \n",
       "...          ...               ...              ...                ...   \n",
       "36724     187019            272143         0.008807                  4   \n",
       "880390    187214            159196         0.739727                  4   \n",
       "653783    187531            208118         0.533928                  4   \n",
       "1004445   188180            202559         0.913877                  4   \n",
       "1057329   194453            206571         0.981858                  4   \n",
       "\n",
       "         click_deviceGroup  click_os  click_country  click_region  \\\n",
       "1096659                  3         2              1            26   \n",
       "1033258                  1        17              1            25   \n",
       "1026746                  3        20              1             8   \n",
       "1022520                  3         2              1             8   \n",
       "1003477                  3         2              1            20   \n",
       "...                    ...       ...            ...           ...   \n",
       "36724                    1        17              1            25   \n",
       "880390                   1        12              1            21   \n",
       "653783                   1        17              1            21   \n",
       "1004445                  3         2              1             6   \n",
       "1057329                  1        17              1            18   \n",
       "\n",
       "         click_referrer_type  \n",
       "1096659                    1  \n",
       "1033258                    2  \n",
       "1026746                    2  \n",
       "1022520                    4  \n",
       "1003477                    2  \n",
       "...                      ...  \n",
       "36724                      5  \n",
       "880390                     2  \n",
       "653783                     2  \n",
       "1004445                    2  \n",
       "1057329                    2  \n",
       "\n",
       "[100 rows x 9 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_click_df.sort_values(['user_id', 'click_timestamp']).groupby(\"user_id\").tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cc54e62a-d2c9-423b-a0d3-75462549b2c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>click_article_id</th>\n",
       "      <th>click_timestamp</th>\n",
       "      <th>click_environment</th>\n",
       "      <th>click_deviceGroup</th>\n",
       "      <th>click_os</th>\n",
       "      <th>click_country</th>\n",
       "      <th>click_region</th>\n",
       "      <th>click_referrer_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [user_id, click_article_id, click_timestamp, click_environment, click_deviceGroup, click_os, click_country, click_region, click_referrer_type]\n",
       "Index: []"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_click_df[all_click_df.user_id == 1835]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4140c2",
   "metadata": {},
   "source": [
    "## 获取文章属性特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cf97263c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取文章id对应的基本属性，保存成字典的形式，方便后面召回阶段，冷启动阶段直接使用\n",
    "def get_item_info_dict(item_info_df):\n",
    "    max_min_scaler = lambda x : (x-np.min(x))/(np.max(x)-np.min(x))\n",
    "    item_info_df['created_at_ts'] = item_info_df[['created_at_ts']].apply(max_min_scaler)\n",
    "    \n",
    "    item_type_dict = dict(zip(item_info_df['click_article_id'], item_info_df['category_id']))\n",
    "    item_words_dict = dict(zip(item_info_df['click_article_id'], item_info_df['words_count']))\n",
    "    item_created_time_dict = dict(zip(item_info_df['click_article_id'], item_info_df['created_at_ts']))\n",
    "    \n",
    "    return item_type_dict, item_words_dict, item_created_time_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f4f42aa4-d731-4b4a-8095-c6b159a8a5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "i_type_d, i_words_d, i_created_time_d = get_item_info_dict(item_info_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ded95585-1e02-46d9-bbfe-94bd1fd15b41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>click_article_id</th>\n",
       "      <th>category_id</th>\n",
       "      <th>created_at_ts</th>\n",
       "      <th>words_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.978432</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.680295</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.689493</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.688942</td>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.685078</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364042</th>\n",
       "      <td>364042</td>\n",
       "      <td>460</td>\n",
       "      <td>0.759646</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364043</th>\n",
       "      <td>364043</td>\n",
       "      <td>460</td>\n",
       "      <td>0.759962</td>\n",
       "      <td>463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364044</th>\n",
       "      <td>364044</td>\n",
       "      <td>460</td>\n",
       "      <td>0.825854</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364045</th>\n",
       "      <td>364045</td>\n",
       "      <td>460</td>\n",
       "      <td>0.986232</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364046</th>\n",
       "      <td>364046</td>\n",
       "      <td>460</td>\n",
       "      <td>0.958152</td>\n",
       "      <td>479</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>364047 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        click_article_id  category_id  created_at_ts  words_count\n",
       "0                      0            0       0.978432          168\n",
       "1                      1            1       0.680295          189\n",
       "2                      2            1       0.689493          250\n",
       "3                      3            1       0.688942          230\n",
       "4                      4            1       0.685078          162\n",
       "...                  ...          ...            ...          ...\n",
       "364042            364042          460       0.759646          144\n",
       "364043            364043          460       0.759962          463\n",
       "364044            364044          460       0.825854          177\n",
       "364045            364045          460       0.986232          126\n",
       "364046            364046          460       0.958152          479\n",
       "\n",
       "[364047 rows x 4 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "74c1b88a-cccb-45db-9d05-6c20585054cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 162, 0.6850776454577139)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aid = 4\n",
    "i_type_d[aid], i_words_d[aid], i_created_time_d[aid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a3fa4c-3f83-4533-be49-94370b90f598",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "46084fdc",
   "metadata": {},
   "source": [
    "## 获取用户历史点击的文章信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f38ecb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_hist_item_info_dict(all_click):\n",
    "    \n",
    "    # 获取user_id对应的用户历史点击文章类型的集合字典\n",
    "    user_hist_item_typs = all_click.groupby('user_id')['category_id'].agg(set).reset_index()\n",
    "    user_hist_item_typs_dict = dict(zip(user_hist_item_typs['user_id'], user_hist_item_typs['category_id']))\n",
    "    \n",
    "    # 获取user_id对应的用户点击文章的集合\n",
    "    user_hist_item_ids_dict = all_click.groupby('user_id')['click_article_id'].agg(set).reset_index()\n",
    "    user_hist_item_ids_dict = dict(zip(user_hist_item_ids_dict['user_id'], user_hist_item_ids_dict['click_article_id']))\n",
    "    \n",
    "    # 获取user_id对应的用户历史点击的文章的平均字数字典\n",
    "    user_hist_item_words = all_click.groupby('user_id')['words_count'].agg('mean').reset_index()\n",
    "    user_hist_item_words_dict = dict(zip(user_hist_item_words['user_id'], user_hist_item_words['words_count']))\n",
    "    \n",
    "    # 获取user_id对应的用户最后一次点击的文章的创建时间\n",
    "    all_click_ = all_click.sort_values('click_timestamp')\n",
    "    user_last_item_created_time = all_click_.groupby('user_id')['created_at_ts'].apply(lambda x: x.iloc[-1]).reset_index()\n",
    "    \n",
    "    max_min_scaler = lambda x : (x-np.min(x))/(np.max(x)-np.min(x))\n",
    "    user_last_item_created_time['created_at_ts'] = user_last_item_created_time[['created_at_ts']].apply(max_min_scaler)\n",
    "    \n",
    "    user_last_item_created_time_dict = dict(zip(user_last_item_created_time['user_id'], \\\n",
    "                                                user_last_item_created_time['created_at_ts']))\n",
    "    \n",
    "    return user_hist_item_typs_dict, user_hist_item_ids_dict, user_hist_item_words_dict, user_last_item_created_time_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0def06d4-348e-4f54-995c-cf94de7504a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>click_article_id</th>\n",
       "      <th>click_timestamp</th>\n",
       "      <th>click_environment</th>\n",
       "      <th>click_deviceGroup</th>\n",
       "      <th>click_os</th>\n",
       "      <th>click_country</th>\n",
       "      <th>click_region</th>\n",
       "      <th>click_referrer_type</th>\n",
       "      <th>category_id</th>\n",
       "      <th>created_at_ts</th>\n",
       "      <th>words_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>194453</td>\n",
       "      <td>156624</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>281</td>\n",
       "      <td>0.961440</td>\n",
       "      <td>244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>194453</td>\n",
       "      <td>272143</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>399</td>\n",
       "      <td>0.961334</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>188180</td>\n",
       "      <td>70646</td>\n",
       "      <td>0.007562</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>136</td>\n",
       "      <td>0.961524</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>188180</td>\n",
       "      <td>199197</td>\n",
       "      <td>0.007588</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>323</td>\n",
       "      <td>0.961510</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>187531</td>\n",
       "      <td>70646</td>\n",
       "      <td>0.008231</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>136</td>\n",
       "      <td>0.961524</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  click_article_id  click_timestamp  click_environment  \\\n",
       "0   194453            156624         0.000000                  4   \n",
       "1   194453            272143         0.000026                  4   \n",
       "2   188180             70646         0.007562                  4   \n",
       "3   188180            199197         0.007588                  4   \n",
       "4   187531             70646         0.008231                  4   \n",
       "\n",
       "   click_deviceGroup  click_os  click_country  click_region  \\\n",
       "0                  1        17              1            18   \n",
       "1                  1        17              1            18   \n",
       "2                  3         2              1             6   \n",
       "3                  3         2              1             6   \n",
       "4                  3        20              1            21   \n",
       "\n",
       "   click_referrer_type  category_id  created_at_ts  words_count  \n",
       "0                    2          281       0.961440          244  \n",
       "1                    2          399       0.961334          184  \n",
       "2                    2          136       0.961524          170  \n",
       "3                    2          323       0.961510          238  \n",
       "4                    2          136       0.961524          170  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined = all_click_df.merge(item_info_df, how='left', on='click_article_id')\n",
    "joined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "976dc59e-ed4d-4758-9780-86f876b8bf2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(499, 12)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ed28eab7-d446-4e70-b2c9-4fe3eae00b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_hist_item_typs_d, u_hist_item_ids_d, u_hist_item_words_d, u_last_item_created_time_d \\\n",
    "    = get_user_hist_item_info_dict(joined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d1d02d73-77f6-4a1a-8b0c-5f3f98d96d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# u_hist_item_typs_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1ef01a10-2d7e-42c8-a9d9-e152c714d2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "uid = 1863"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d4d0a3a8-b741-4beb-9e57-88bc36fe685c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>click_article_id</th>\n",
       "      <th>click_timestamp</th>\n",
       "      <th>click_environment</th>\n",
       "      <th>click_deviceGroup</th>\n",
       "      <th>click_os</th>\n",
       "      <th>click_country</th>\n",
       "      <th>click_region</th>\n",
       "      <th>click_referrer_type</th>\n",
       "      <th>category_id</th>\n",
       "      <th>created_at_ts</th>\n",
       "      <th>words_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>1863</td>\n",
       "      <td>70429</td>\n",
       "      <td>0.987307</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>136</td>\n",
       "      <td>0.964645</td>\n",
       "      <td>275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>1863</td>\n",
       "      <td>96877</td>\n",
       "      <td>0.987333</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>209</td>\n",
       "      <td>0.964660</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_id  click_article_id  click_timestamp  click_environment  \\\n",
       "487     1863             70429         0.987307                  4   \n",
       "488     1863             96877         0.987333                  4   \n",
       "\n",
       "     click_deviceGroup  click_os  click_country  click_region  \\\n",
       "487                  3         2              1            26   \n",
       "488                  3         2              1            26   \n",
       "\n",
       "     click_referrer_type  category_id  created_at_ts  words_count  \n",
       "487                    1          136       0.964645          275  \n",
       "488                    1          209       0.964660          192  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = joined[joined.user_id == uid]\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4e80951a-d23e-4b75-919b-16df9c583990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{136, 209}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_hist_item_typs_d[uid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1050841a-5f2a-41c9-a1ea-2f0a21ccf644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{70429, 96877}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_hist_item_ids_d[uid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "87a8854f-d467-4746-94ea-1135d14f8ca4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(233.5, 233.5)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_hist_item_words_d[uid], d.words_count.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "af0a58ae-6ea3-41c0-b2e9-f945483e2ef7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9997721947323628"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_last_item_created_time_d[uid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe062b86-5519-4ded-ad32-2749e6a28bf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c126600b",
   "metadata": {},
   "source": [
    "## 获取点击次数最多的Top-k个文章"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "57f043fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取近期点击最多的文章\n",
    "def get_item_topk_click(click_df, k):\n",
    "    topk_click = click_df['click_article_id'].value_counts().index[:k]\n",
    "    return topk_click\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "45d248fa-8c8f-4c3e-9c16-38588b3db091",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([234698, 96210, 336223], dtype='int64')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_item_topk_click(all_click_df, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a7c7bde4-cff1-4163-a814-afbbd43d774f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "234698    7\n",
       "96210     7\n",
       "336223    7\n",
       "Name: click_article_id, dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_click_df.click_article_id.value_counts()[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af32e38",
   "metadata": {},
   "source": [
    "## 定义多路召回字典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0efce6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取文章的属性信息，保存成字典的形式方便查询\n",
    "item_type_dict, item_words_dict, item_created_time_dict = get_item_info_dict(item_info_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "758e8492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一个多路召回的字典，将各路召回的结果都保存在这个字典当中\n",
    "user_multi_recall_dict =  {'itemcf_sim_itemcf_recall': {},\n",
    "                           'embedding_sim_item_recall': {},\n",
    "                           'youtubednn_recall': {},\n",
    "                           'youtubednn_usercf_recall': {}, \n",
    "                           'cold_start_recall': {}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0f39df9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提取最后一次点击作为召回评估，如果不需要做召回评估直接使用全量的训练集进行召回(线下验证模型)\n",
    "# 如果不是召回评估，直接使用全量数据进行召回，不用将最后一次提取出来\n",
    "trn_hist_click_df, trn_last_click_df = get_hist_and_last_click(all_click_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5af92b",
   "metadata": {},
   "source": [
    "## 召回效果评估\n",
    "做完了召回有时候也需要对当前的召回方法或者参数进行调整以达到更好的召回效果，因为召回的结果决定了最终排序的上限，下面也会提供一个召回评估的方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "0eb3b318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 依次评估召回的前10, 20, 30, 40, 50个文章中的击中率\n",
    "def metrics_recall(user_recall_items_dict, trn_last_click_df, topk=5):\n",
    "    last_click_item_dict = dict(zip(trn_last_click_df['user_id'], trn_last_click_df['click_article_id']))\n",
    "    user_num = len(user_recall_items_dict)\n",
    "    \n",
    "    # for k in range(10, topk+1, 10):\n",
    "    for k in [1, 5, 10 , 20]:\n",
    "        hit_num = 0\n",
    "        for user, item_list in user_recall_items_dict.items():\n",
    "            # 获取前k个召回的结果\n",
    "            tmp_recall_items = [x[0] for x in user_recall_items_dict[user][:k]]\n",
    "            if last_click_item_dict[user] in set(tmp_recall_items):\n",
    "                hit_num += 1\n",
    "        \n",
    "        hit_rate = round(hit_num * 1.0 / user_num, 5)\n",
    "        print(' topk: ', k, ' : ', 'hit_num: ', hit_num, 'hit_rate: ', hit_rate, 'user_num : ', user_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a29b5ff-2637-47f1-b786-bcbcde310d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d = dict(zip(click_last_df['user_id'],[ click_last_df['click_article_id']]))\n",
    "\n",
    "# metrics_recall(d, click_last_df, topk=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4468fe",
   "metadata": {},
   "source": [
    "# 计算相似性矩阵\n",
    "这一部分主要是通过协同过滤以及向量检索得到相似性矩阵，相似性矩阵主要分为user2user和item2item，下面依次获取基于itemCF的item2item的相似性矩阵。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9459daec",
   "metadata": {},
   "source": [
    "## itemCF i2i_sim\n",
    "借鉴KDD2020的去偏商品推荐，在计算item2item相似性矩阵时，使用关联规则，使得计算的文章的相似性还考虑到了:\n",
    "\n",
    "1. 用户点击的时间权重\n",
    "2. 用户点击的顺序权重\n",
    "3. 文章创建的时间权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f4831f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def itemcf_sim(df, item_created_time_dict):\n",
    "    \"\"\"\n",
    "        文章与文章之间的相似性矩阵计算\n",
    "        :param df: 数据表\n",
    "        :item_created_time_dict:  文章创建时间的字典\n",
    "        return : 文章与文章的相似性矩阵\n",
    "        \n",
    "        思路: 基于物品的协同过滤(详细请参考上一期推荐系统基础的组队学习) + 关联规则\n",
    "    \"\"\"\n",
    "    \n",
    "    user_item_time_dict = get_user_item_time(df)\n",
    "    \n",
    "    # 计算物品相似度\n",
    "    i2i_sim = {}\n",
    "    item_cnt = defaultdict(int)\n",
    "    for user, item_time_list in tqdm(user_item_time_dict.items()):\n",
    "        # 在基于商品的协同过滤优化的时候可以考虑时间因素\n",
    "        for loc1, (i, i_click_time) in enumerate(item_time_list):\n",
    "            item_cnt[i] += 1\n",
    "            i2i_sim.setdefault(i, {})\n",
    "            for loc2, (j, j_click_time) in enumerate(item_time_list):\n",
    "                if(i == j):\n",
    "                    continue\n",
    "                    \n",
    "                # 考虑文章的正向顺序点击和反向顺序点击    \n",
    "                loc_alpha = 1.0 if loc2 > loc1 else 0.7\n",
    "                # 位置信息权重，其中的参数可以调节\n",
    "                loc_weight = loc_alpha * (0.9 ** (np.abs(loc2 - loc1) - 1))\n",
    "                # 点击时间权重，其中的参数可以调节\n",
    "                click_time_weight = np.exp(0.7 ** np.abs(i_click_time - j_click_time))\n",
    "                # 两篇文章创建时间的权重，其中的参数可以调节\n",
    "                created_time_weight = np.exp(0.8 ** np.abs(item_created_time_dict[i] - item_created_time_dict[j]))\n",
    "                i2i_sim[i].setdefault(j, 0)\n",
    "                # 考虑多种因素的权重计算最终的文章之间的相似度\n",
    "                i2i_sim[i][j] += loc_weight * click_time_weight * created_time_weight / math.log(len(item_time_list) + 1)\n",
    "                \n",
    "    i2i_sim_ = i2i_sim.copy()\n",
    "    for i, related_items in i2i_sim.items():\n",
    "        for j, wij in related_items.items():\n",
    "            i2i_sim_[i][j] = wij / math.sqrt(item_cnt[i] * item_cnt[j])\n",
    "    \n",
    "    # 将得到的相似性矩阵保存到本地\n",
    "    pickle.dump(i2i_sim_, open(save_path + 'itemcf_i2i_sim.pkl', 'wb'))\n",
    "    \n",
    "    return i2i_sim_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b449760d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 3115.64it/s]\n"
     ]
    }
   ],
   "source": [
    "i2i_sim = itemcf_sim(all_click_df, item_created_time_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "186b1ea6-3c29-4b15-a614-c438ff2266ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i2i_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4f0a1be9-cdfd-4ce3-b155-c9e290d6407f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{96877: 3.8830981684320207,\n",
       " 284547: 0.5840232003344622,\n",
       " 285342: 0.9177169395184708,\n",
       " 235804: 1.0593614296216842,\n",
       " 124228: 0.8323722402050069,\n",
       " 36394: 0.9248958067885555,\n",
       " 156625: 1.4533989965962326,\n",
       " 211941: 1.6148776065227153,\n",
       " 159195: 2.794230287085938,\n",
       " 352979: 1.9381841918171607}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i2i_sim[70429]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b9a0919a-4aa9-435f-bca0-174816a87cbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>click_article_id</th>\n",
       "      <th>click_timestamp</th>\n",
       "      <th>click_environment</th>\n",
       "      <th>click_deviceGroup</th>\n",
       "      <th>click_os</th>\n",
       "      <th>click_country</th>\n",
       "      <th>click_region</th>\n",
       "      <th>click_referrer_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [user_id, click_article_id, click_timestamp, click_environment, click_deviceGroup, click_os, click_country, click_region, click_referrer_type]\n",
       "Index: []"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_click_df[all_click_df.click_article_id == 97530]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b16a3d55-db7b-4e98-96f0-f3d71a8babb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>click_article_id</th>\n",
       "      <th>click_timestamp</th>\n",
       "      <th>click_environment</th>\n",
       "      <th>click_deviceGroup</th>\n",
       "      <th>click_os</th>\n",
       "      <th>click_country</th>\n",
       "      <th>click_region</th>\n",
       "      <th>click_referrer_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [user_id, click_article_id, click_timestamp, click_environment, click_deviceGroup, click_os, click_country, click_region, click_referrer_type]\n",
       "Index: []"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_click_df[all_click_df.user_id == 5440]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db8e371-6d9a-480c-8232-df2fba8d8741",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f7ad2569",
   "metadata": {},
   "source": [
    "## userCF u2u_sim\n",
    "在计算用户之间的相似度的时候，也可以使用一些简单的关联规则，比如用户活跃度权重，这里将用户的点击次数作为用户活跃度的指标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8e6375a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_activate_degree_dict(all_click_df):\n",
    "    all_click_df_ = all_click_df.groupby('user_id')['click_article_id'].count().reset_index()\n",
    "    \n",
    "    # 用户活跃度归一化\n",
    "    mm = MinMaxScaler()\n",
    "    all_click_df_['click_article_id'] = mm.fit_transform(all_click_df_[['click_article_id']])\n",
    "    user_activate_degree_dict = dict(zip(all_click_df_['user_id'], all_click_df_['click_article_id']))\n",
    "    \n",
    "    return user_activate_degree_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6807737a-f49d-4415-aebd-c422015957dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ua_d = get_user_activate_degree_dict(all_click_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6441f081-005f-4a38-93fb-76bf0f02b427",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{u: a for u, a in ua_d.items() if a == 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "62390ca5-d581-4175-9a7c-775d3d9eb391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id\n",
       "165601    26\n",
       "157329    22\n",
       "129308    19\n",
       "63762     17\n",
       "65426     16\n",
       "Name: click_article_id, dtype: int64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_click_df.groupby(\"user_id\").click_article_id.count().nlargest(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6572dd3e-f126-4bf5-b345-9fc301b49bbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "379507f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def usercf_sim(all_click_df, user_activate_degree_dict):\n",
    "    \"\"\"\n",
    "        用户相似性矩阵计算\n",
    "        :param all_click_df: 数据表\n",
    "        :param user_activate_degree_dict: 用户活跃度的字典\n",
    "        return 用户相似性矩阵\n",
    "        \n",
    "        思路: 基于用户的协同过滤(详细请参考上一期推荐系统基础的组队学习) + 关联规则\n",
    "    \"\"\"\n",
    "    # {item1: {user1: time1, user2: time2...}...}\n",
    "    item_user_time_dict = get_item_user_time_dict(all_click_df)\n",
    "    \n",
    "    u2u_sim = {}\n",
    "    user_cnt = defaultdict(int)\n",
    "    for item, user_time_list in tqdm(item_user_time_dict.items()):\n",
    "        for u, click_time in user_time_list:\n",
    "            user_cnt[u] += 1\n",
    "            u2u_sim.setdefault(u, {})\n",
    "            for v, click_time in user_time_list:\n",
    "                u2u_sim[u].setdefault(v, 0)\n",
    "                if u == v:\n",
    "                    continue\n",
    "                # 用户平均活跃度作为活跃度的权重，这里的式子也可以改善\n",
    "                activate_weight = 100 * 0.5 * (user_activate_degree_dict[u] + user_activate_degree_dict[v])   \n",
    "                u2u_sim[u][v] += activate_weight / math.log(len(user_time_list) + 1)\n",
    "    \n",
    "    u2u_sim_ = u2u_sim.copy()\n",
    "    for u, related_users in u2u_sim.items():\n",
    "        for v, wij in related_users.items():\n",
    "            u2u_sim_[u][v] = wij / math.sqrt(user_cnt[u] * user_cnt[v])\n",
    "    \n",
    "    # 将得到的相似性矩阵保存到本地\n",
    "    pickle.dump(u2u_sim_, open(save_path + 'usercf_u2u_sim.pkl', 'wb'))\n",
    "\n",
    "    return u2u_sim_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "cdb52139",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 345/345 [00:00<00:00, 379102.67it/s]\n"
     ]
    }
   ],
   "source": [
    "# 由于usercf计算时候太耗费内存了，这里就不直接运行了\n",
    "# 如果是采样的话，是可以运行的\n",
    "user_activate_degree_dict = get_user_activate_degree_dict(all_click_df)\n",
    "u2u_sim = usercf_sim(all_click_df, user_activate_degree_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "32627281-e0c3-46de-9935-05b0aee9d33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# u2u_sim[36656]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03aabed4",
   "metadata": {},
   "source": [
    "## item embedding sim\n",
    "使用Embedding计算item之间的相似度是为了后续冷启动的时候可以获取未出现在点击数据中的文章，后面有对冷启动专门的介绍，这里简单的说一下faiss。\n",
    "\n",
    "faiss是Facebook的AI团队开源的一套用于做聚类或者相似性搜索的软件库，底层是用C++实现。Faiss因为超级优越的性能，被广泛应用于推荐相关的业务当中.\n",
    "\n",
    "faiss工具包一般使用在推荐系统中的向量召回部分。在做向量召回的时候要么是u2u,u2i或者i2i，这里的u和i指的是user和item.我们知道在实际的场景中user和item的数量都是海量的，我们最容易想到的基于向量相似度的召回就是使用两层循环遍历user列表或者item列表计算两个向量的相似度，但是这样做在面对海量数据是不切实际的，faiss就是用来加速计算某个查询向量最相似的topk个索引向量。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8d1c6b",
   "metadata": {},
   "source": [
    "faiss查询的原理：\n",
    "\n",
    "faiss使用了PCA和PQ(Product quantization乘积量化)两种技术进行向量压缩和编码，当然还使用了其他的技术进行优化，但是PCA和PQ是其中最核心部分。\n",
    "\n",
    "1. PCA降维算法细节参考下面这个链接进行学习\n",
    "    - [主成分分析（PCA）原理总结](https://www.cnblogs.com/pinard/p/6239403.html)\n",
    "\n",
    "2. PQ编码的细节下面这个链接进行学习\n",
    "    - [实例理解product quantization算法](http://www.fabwrite.com/productquantization)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b28ec6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 向量检索相似度计算\n",
    "# topk指的是每个item, faiss搜索后返回最相似的topk个item\n",
    "def embdding_sim(click_df, item_emb_df, save_path, topk):\n",
    "    \"\"\"\n",
    "        基于内容的文章embedding相似性矩阵计算\n",
    "        :param click_df: 数据表\n",
    "        :param item_emb_df: 文章的embedding\n",
    "        :param save_path: 保存路径\n",
    "        :patam topk: 找最相似的topk篇\n",
    "        return 文章相似性矩阵\n",
    "        \n",
    "        思路: 对于每一篇文章， 基于embedding的相似性返回topk个与其最相似的文章， 只不过由于文章数量太多，这里用了faiss进行加速\n",
    "    \"\"\"\n",
    "    \n",
    "    # 文章索引与文章id的字典映射\n",
    "    item_idx_2_rawid_dict = dict(zip(item_emb_df.index, item_emb_df['article_id']))\n",
    "    \n",
    "    item_emb_cols = [x for x in item_emb_df.columns if 'emb' in x]\n",
    "    item_emb_np = np.ascontiguousarray(item_emb_df[item_emb_cols].values, dtype=np.float32)\n",
    "    # 向量进行单位化\n",
    "    item_emb_np = item_emb_np / np.linalg.norm(item_emb_np, axis=1, keepdims=True)\n",
    "    \n",
    "    # 建立faiss索引\n",
    "    item_index = faiss.IndexFlatIP(item_emb_np.shape[1])\n",
    "    item_index.add(item_emb_np)\n",
    "    # 相似度查询，给每个索引位置上的向量返回topk个item以及相似度\n",
    "    sim, idx = item_index.search(item_emb_np, topk) # 返回的是列表\n",
    "    \n",
    "    # 将向量检索的结果保存成原始id的对应关系\n",
    "    item_sim_dict = collections.defaultdict(dict)\n",
    "    for target_idx, sim_value_list, rele_idx_list in tqdm(zip(range(len(item_emb_np)), sim, idx)):\n",
    "        target_raw_id = item_idx_2_rawid_dict[target_idx]\n",
    "        # 从1开始是为了去掉商品本身, 所以最终获得的相似商品只有topk-1\n",
    "        for rele_idx, sim_value in zip(rele_idx_list[1:], sim_value_list[1:]): \n",
    "            rele_raw_id = item_idx_2_rawid_dict[rele_idx]\n",
    "            item_sim_dict[target_raw_id][rele_raw_id] = item_sim_dict.get(target_raw_id, {}).get(rele_raw_id, 0) + sim_value\n",
    "    \n",
    "    # 保存i2i相似度矩阵\n",
    "    pickle.dump(item_sim_dict, open(save_path + 'emb_i2i_sim.pkl', 'wb'))   \n",
    "    \n",
    "    return item_sim_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c0be26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# item_emb_df = pd.read_csv(data_path + '/articles_emb.csv')\n",
    "# emb_i2i_sim = embdding_sim(all_click_df, item_emb_df, save_path, topk=10) # topk可以自行设置\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5fce0c",
   "metadata": {},
   "source": [
    "# 召回"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05475edf",
   "metadata": {},
   "source": [
    "这个就是我们开篇提到的那个问题， 面的36万篇文章， 20多万用户的推荐， 我们又有哪些策略来缩减问题的规模？ 我们就可以再召回阶段筛选出用户对于点击文章的候选集合， 从而降低问题的规模。召回常用的策略：\n",
    "\n",
    "- Youtube DNN 召回\n",
    "- 基于文章的召回\n",
    "    - 文章的协同过滤\n",
    "    - 基于文章embedding的召回\n",
    "- 基于用户的召回\n",
    "    - 用户的协同过滤\n",
    "    - 用户embedding\n",
    "    \n",
    "上面的各种召回方式一部分在基于用户已经看得文章的基础上去召回与这些文章相似的一些文章， 而这个相似性的计算方式不同， 就得到了不同的召回方式， 比如文章的协同过滤， 文章内容的embedding等。还有一部分是根据用户的相似性进行推荐，对于某用户推荐与其相似的其他用户看过的文章，比如用户的协同过滤和用户embedding。 还有一种思路是类似矩阵分解的思路，先计算出用户和文章的embedding之后，就可以直接算用户和文章的相似度， 根据这个相似度进行推荐， 比如YouTube DNN。 我们下面详细来看一下每一个召回方法："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9da38a",
   "metadata": {},
   "source": [
    "## YoutubeDNN召回\n",
    "(这一步是直接获取用户召回的候选文章列表)\n",
    "\n",
    "\n",
    "Youtubednn召回架构"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693d4a10",
   "metadata": {},
   "source": [
    "![alt text](images/youtube_dnn.png \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cce0ab",
   "metadata": {},
   "source": [
    "关于YoutubeDNN原理和应用推荐看王喆的两篇博客：\n",
    "\n",
    "1. 重读Youtube深度学习推荐系统论文，字字珠玑，惊为神文\n",
    "2. YouTube深度学习推荐系统的十大工程问题\n",
    "参考文献:\n",
    "\n",
    "- https://zhuanlan.zhihu.com/p/52169807 (YouTubeDNN原理)\n",
    "- https://zhuanlan.zhihu.com/p/26306795 (Word2Vec知乎众赞文章) --- word2vec放到排序中的w2v的介绍部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e3b3ad87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取双塔召回时的训练验证数据\n",
    "# negsample指的是通过滑窗构建样本的时候，负样本的数量\n",
    "def gen_data_set(data, negsample=0):\n",
    "    data.sort_values(\"click_timestamp\", inplace=True)\n",
    "    item_ids = data['click_article_id'].unique()\n",
    "\n",
    "    train_set = []\n",
    "    test_set = []\n",
    "    for reviewerID, hist in tqdm(data.groupby('user_id')):\n",
    "        pos_list = hist['click_article_id'].tolist()\n",
    "        \n",
    "        if negsample > 0:\n",
    "            candidate_set = list(set(item_ids) - set(pos_list))   # 用户没看过的文章里面选择负样本\n",
    "            neg_list = np.random.choice(candidate_set,size=len(pos_list)*negsample,replace=True)  # 对于每个正样本，选择n个负样本\n",
    "            \n",
    "        # 长度只有一个的时候，需要把这条数据也放到训练集中，不然的话最终学到的embedding就会有缺失\n",
    "        if len(pos_list) == 1:\n",
    "            train_set.append((reviewerID, [pos_list[0]], pos_list[0],1,len(pos_list)))\n",
    "            test_set.append((reviewerID, [pos_list[0]], pos_list[0],1,len(pos_list)))\n",
    "            \n",
    "        # 滑窗构造正负样本\n",
    "        for i in range(1, len(pos_list)):\n",
    "            hist = pos_list[:i]\n",
    "            \n",
    "            if i != len(pos_list) - 1:\n",
    "                train_set.append((reviewerID, hist[::-1], pos_list[i], 1, len(hist[::-1])))  # 正样本 [user_id, his_item, pos_item, label, len(his_item)]\n",
    "                for negi in range(negsample):\n",
    "                    train_set.append((reviewerID, hist[::-1], neg_list[i*negsample+negi], 0,len(hist[::-1]))) # 负样本 [user_id, his_item, neg_item, label, len(his_item)]\n",
    "            else:\n",
    "                # 将最长的那一个序列长度作为测试数据\n",
    "                test_set.append((reviewerID, hist[::-1], pos_list[i],1,len(hist[::-1])))\n",
    "                \n",
    "    random.shuffle(train_set)\n",
    "    random.shuffle(test_set)\n",
    "    \n",
    "    return train_set, test_set\n",
    "\n",
    "# 将输入的数据进行padding，使得序列特征的长度都一致\n",
    "def gen_model_input(train_set,user_profile,seq_max_len):\n",
    "\n",
    "    train_uid = np.array([line[0] for line in train_set])\n",
    "    train_seq = [line[1] for line in train_set]\n",
    "    train_iid = np.array([line[2] for line in train_set])\n",
    "    train_label = np.array([line[3] for line in train_set])\n",
    "    train_hist_len = np.array([line[4] for line in train_set])\n",
    "\n",
    "    train_seq_pad = pad_sequences(train_seq, maxlen=seq_max_len, padding='post', truncating='post', value=0)\n",
    "    train_model_input = {\"user_id\": train_uid, \"click_article_id\": train_iid, \"hist_article_id\": train_seq_pad,\n",
    "                         \"hist_len\": train_hist_len}\n",
    "\n",
    "    return train_model_input, train_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "561b28cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def youtubednn_u2i_dict(data, topk=20):    \n",
    "    sparse_features = [\"click_article_id\", \"user_id\"]\n",
    "    SEQ_LEN = 30 # 用户点击序列的长度，短的填充，长的截断\n",
    "    \n",
    "    user_profile_ = data[[\"user_id\"]].drop_duplicates('user_id')\n",
    "    item_profile_ = data[[\"click_article_id\"]].drop_duplicates('click_article_id')  \n",
    "    \n",
    "    # 类别编码\n",
    "    features = [\"click_article_id\", \"user_id\"]\n",
    "    feature_max_idx = {}\n",
    "    \n",
    "    for feature in features:\n",
    "        lbe = LabelEncoder()\n",
    "        data[feature] = lbe.fit_transform(data[feature])\n",
    "        feature_max_idx[feature] = data[feature].max() + 1\n",
    "    \n",
    "    # 提取user和item的画像，这里具体选择哪些特征还需要进一步的分析和考虑\n",
    "    user_profile = data[[\"user_id\"]].drop_duplicates('user_id')\n",
    "    item_profile = data[[\"click_article_id\"]].drop_duplicates('click_article_id')  \n",
    "    \n",
    "    user_index_2_rawid = dict(zip(user_profile['user_id'], user_profile_['user_id']))\n",
    "    item_index_2_rawid = dict(zip(item_profile['click_article_id'], item_profile_['click_article_id']))\n",
    "    \n",
    "    # 划分训练和测试集\n",
    "    # 由于深度学习需要的数据量通常都是非常大的，所以为了保证召回的效果，往往会通过滑窗的形式扩充训练样本\n",
    "    train_set, test_set = gen_data_set(data, 0)\n",
    "    # 整理输入数据，具体的操作可以看上面的函数\n",
    "    train_model_input, train_label = gen_model_input(train_set, user_profile, SEQ_LEN)\n",
    "    test_model_input, test_label = gen_model_input(test_set, user_profile, SEQ_LEN)\n",
    "    \n",
    "    # 确定Embedding的维度\n",
    "    embedding_dim = 16\n",
    "    \n",
    "    # 将数据整理成模型可以直接输入的形式\n",
    "    user_feature_columns = [SparseFeat('user_id', feature_max_idx['user_id'], embedding_dim),\n",
    "                            VarLenSparseFeat(SparseFeat('hist_article_id', feature_max_idx['click_article_id'], embedding_dim,\n",
    "                                                        embedding_name=\"click_article_id\"), SEQ_LEN, 'mean', 'hist_len'),]\n",
    "    item_feature_columns = [SparseFeat('click_article_id', feature_max_idx['click_article_id'], embedding_dim)]\n",
    "    \n",
    "    # 模型的定义 \n",
    "    # num_sampled: 负采样时的样本数量\n",
    "    model = YoutubeDNN(user_feature_columns, item_feature_columns, num_sampled=5, user_dnn_hidden_units=(64, embedding_dim))\n",
    "    # 模型编译\n",
    "    model.compile(optimizer=\"adam\", loss=sampledsoftmaxloss)  \n",
    "    \n",
    "    # 模型训练，这里可以定义验证集的比例，如果设置为0的话就是全量数据直接进行训练\n",
    "    history = model.fit(train_model_input, train_label, batch_size=256, epochs=1, verbose=1, validation_split=0.0)\n",
    "    \n",
    "    # 训练完模型之后,提取训练的Embedding，包括user端和item端\n",
    "    test_user_model_input = test_model_input\n",
    "    all_item_model_input = {\"click_article_id\": item_profile['click_article_id'].values}\n",
    "\n",
    "    user_embedding_model = Model(inputs=model.user_input, outputs=model.user_embedding)\n",
    "    item_embedding_model = Model(inputs=model.item_input, outputs=model.item_embedding)\n",
    "    \n",
    "    # 保存当前的item_embedding 和 user_embedding 排序的时候可能能够用到，但是需要注意保存的时候需要和原始的id对应\n",
    "    user_embs = user_embedding_model.predict(test_user_model_input, batch_size=2 ** 12)\n",
    "    item_embs = item_embedding_model.predict(all_item_model_input, batch_size=2 ** 12)\n",
    "    \n",
    "    # embedding保存之前归一化一下\n",
    "    user_embs = user_embs / np.linalg.norm(user_embs, axis=1, keepdims=True)\n",
    "    item_embs = item_embs / np.linalg.norm(item_embs, axis=1, keepdims=True)\n",
    "    \n",
    "    # 将Embedding转换成字典的形式方便查询\n",
    "    raw_user_id_emb_dict = {user_index_2_rawid[k]: \\\n",
    "                                v for k, v in zip(user_profile['user_id'], user_embs)}\n",
    "    raw_item_id_emb_dict = {item_index_2_rawid[k]: \\\n",
    "                                v for k, v in zip(item_profile['click_article_id'], item_embs)}\n",
    "    # 将Embedding保存到本地\n",
    "    pickle.dump(raw_user_id_emb_dict, open(save_path + 'user_youtube_emb.pkl', 'wb'))\n",
    "    pickle.dump(raw_item_id_emb_dict, open(save_path + 'item_youtube_emb.pkl', 'wb'))\n",
    "    \n",
    "    # faiss紧邻搜索，通过user_embedding 搜索与其相似性最高的topk个item\n",
    "    index = faiss.IndexFlatIP(embedding_dim)\n",
    "    # 上面已经进行了归一化，这里可以不进行归一化了\n",
    "#     faiss.normalize_L2(user_embs)\n",
    "#     faiss.normalize_L2(item_embs)\n",
    "    index.add(item_embs) # 将item向量构建索引\n",
    "    sim, idx = index.search(np.ascontiguousarray(user_embs), topk) # 通过user去查询最相似的topk个item\n",
    "    \n",
    "    user_recall_items_dict = collections.defaultdict(dict)\n",
    "    for target_idx, sim_value_list, rele_idx_list in tqdm(zip(test_user_model_input['user_id'], sim, idx)):\n",
    "        target_raw_id = user_index_2_rawid[target_idx]\n",
    "        # 从1开始是为了去掉商品本身, 所以最终获得的相似商品只有topk-1\n",
    "        for rele_idx, sim_value in zip(rele_idx_list[1:], sim_value_list[1:]): \n",
    "            rele_raw_id = item_index_2_rawid[rele_idx]\n",
    "            user_recall_items_dict[target_raw_id][rele_raw_id] = user_recall_items_dict.get(target_raw_id, {})\\\n",
    "                                                                    .get(rele_raw_id, 0) + sim_value\n",
    "            \n",
    "    user_recall_items_dict = {k: sorted(v.items(), key=lambda x: x[1], reverse=True) for k, v in user_recall_items_dict.items()}\n",
    "    # 将召回的结果进行排序\n",
    "    \n",
    "    # 保存召回的结果\n",
    "    # 这里是直接通过向量的方式得到了召回结果，相比于上面的召回方法，上面的只是得到了i2i及u2u的相似性矩阵，还需要进行协同过滤召回才能得到召回结果\n",
    "    # 可以直接对这个召回结果进行评估，为了方便可以统一写一个评估函数对所有的召回结果进行评估\n",
    "    pickle.dump(user_recall_items_dict, open(save_path + 'youtube_u2i_dict.pkl', 'wb'))\n",
    "    return user_recall_items_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301c8642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 由于这里需要做召回评估，所以讲训练集中的最后一次点击都提取了出来\n",
    "if not metric_recall:\n",
    "    user_multi_recall_dict['youtubednn_recall'] = youtubednn_u2i_dict(all_click_df, topk=20)\n",
    "else:\n",
    "    trn_hist_click_df, trn_last_click_df = get_hist_and_last_click(all_click_df)\n",
    "    user_multi_recall_dict['youtubednn_recall'] = youtubednn_u2i_dict(trn_hist_click_df, topk=20)\n",
    "    # 召回效果评估\n",
    "    metrics_recall(user_multi_recall_dict['youtubednn_recall'], trn_last_click_df, topk=20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84bd4380",
   "metadata": {},
   "source": [
    "## itemCF recall\n",
    "上面已经通过协同过滤，Embedding检索的方式得到了文章的相似度矩阵，下面使用协同过滤的思想，给用户召回与其历史文章相似的文章。 这里在召回的时候，也是用了关联规则的方式：\n",
    "\n",
    "- 考虑相似文章与历史点击文章顺序的权重(细节看代码)\n",
    "- 考虑文章创建时间的权重，也就是考虑相似文章与历史点击文章创建时间差的权重\n",
    "- 考虑文章内容相似度权重(使用Embedding计算相似文章相似度，但是这里需要注意，在Embedding的时候并没有计算所有商品两两之间的相似度，所以相似的文章与历史点击文章不存在相似度，需要做特殊处理)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ef0cfa6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基于商品的召回i2i\n",
    "def item_based_recommend(user_id, user_item_time_dict, i2i_sim, sim_item_topk, \n",
    "                         recall_item_num, item_topk_click, item_created_time_dict, emb_i2i_sim):\n",
    "    \"\"\"\n",
    "        基于文章协同过滤的召回\n",
    "        :param user_id: 用户id\n",
    "        :param user_item_time_dict: 字典, 根据点击时间获取用户的点击文章序列   {user1: {item1: time1, item2: time2..}...}\n",
    "        :param i2i_sim: 字典，文章相似性矩阵\n",
    "        :param sim_item_topk: 整数， 选择与当前文章最相似的前k篇文章\n",
    "        :param recall_item_num: 整数， 最后的召回文章数量\n",
    "        :param item_topk_click: 列表，点击次数最多的文章列表，用户召回补全\n",
    "        :param emb_i2i_sim: 字典基于内容embedding算的文章相似矩阵\n",
    "        \n",
    "        return: 召回的文章列表 {item1:score1, item2: score2...}\n",
    "        \n",
    "    \"\"\"\n",
    "    # 获取用户历史交互的文章\n",
    "    user_hist_items = user_item_time_dict[user_id]\n",
    "    \n",
    "    item_rank = {}\n",
    "    for loc, (i, click_time) in enumerate(user_hist_items):\n",
    "        for j, wij in sorted(i2i_sim[i].items(), key=lambda x: x[1], reverse=True)[:sim_item_topk]:\n",
    "            if j in user_hist_items:\n",
    "                continue\n",
    "            \n",
    "            # 文章创建时间差权重\n",
    "            created_time_weight = np.exp(0.8 ** np.abs(item_created_time_dict[i] - item_created_time_dict[j]))\n",
    "            # 相似文章和历史点击文章序列中历史文章所在的位置权重\n",
    "            loc_weight = (0.9 ** (len(user_hist_items) - loc))\n",
    "            \n",
    "            content_weight = 1.0\n",
    "            if emb_i2i_sim:\n",
    "                if emb_i2i_sim.get(i, {}).get(j, None) is not None:\n",
    "                    content_weight += emb_i2i_sim[i][j]\n",
    "                if emb_i2i_sim.get(j, {}).get(i, None) is not None:\n",
    "                    content_weight += emb_i2i_sim[j][i]\n",
    "                \n",
    "            item_rank.setdefault(j, 0)\n",
    "            item_rank[j] += created_time_weight * loc_weight * content_weight * wij\n",
    "    \n",
    "    # 不足10个，用热门商品补全\n",
    "    if len(item_rank) < recall_item_num:\n",
    "        for i, item in enumerate(item_topk_click):\n",
    "            if item in item_rank.items(): # 填充的item应该不在原来的列表中\n",
    "                continue\n",
    "            item_rank[item] = - i - 100 # 随便给个负数就行\n",
    "            if len(item_rank) == recall_item_num:\n",
    "                break\n",
    "    \n",
    "    item_rank = sorted(item_rank.items(), key=lambda x: x[1], reverse=True)[:recall_item_num]\n",
    "        \n",
    "    return item_rank\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4525c3c9",
   "metadata": {},
   "source": [
    "## itemCF sim召回\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "78d612a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 5799.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " topk:  1  :  hit_num:  80 hit_rate:  0.8 user_num :  100\n",
      " topk:  5  :  hit_num:  94 hit_rate:  0.94 user_num :  100\n",
      " topk:  10  :  hit_num:  99 hit_rate:  0.99 user_num :  100\n",
      " topk:  20  :  hit_num:  99 hit_rate:  0.99 user_num :  100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 先进行itemcf召回, 为了召回评估，所以提取最后一次点击\n",
    "\n",
    "if metric_recall:\n",
    "    trn_hist_click_df, trn_last_click_df = get_hist_and_last_click(all_click_df)\n",
    "else:\n",
    "    trn_hist_click_df = all_click_df\n",
    "\n",
    "user_recall_items_dict = collections.defaultdict(dict)\n",
    "user_item_time_dict = get_user_item_time(trn_hist_click_df)\n",
    "\n",
    "i2i_sim = pickle.load(open(save_path + 'itemcf_i2i_sim.pkl', 'rb'))\n",
    "# emb_i2i_sim = pickle.load(open(save_path + 'emb_i2i_sim.pkl', 'rb'))\n",
    "emb_i2i_sim = None\n",
    "\n",
    "sim_item_topk = 20\n",
    "recall_item_num = 10\n",
    "item_topk_click = get_item_topk_click(trn_hist_click_df, k=50)\n",
    "\n",
    "for user in tqdm(trn_hist_click_df['user_id'].unique()):\n",
    "    user_recall_items_dict[user] = item_based_recommend(user, user_item_time_dict, \\\n",
    "                                                        i2i_sim, sim_item_topk, recall_item_num, \\\n",
    "                                                        item_topk_click, item_created_time_dict, emb_i2i_sim)\n",
    "\n",
    "user_multi_recall_dict['itemcf_sim_itemcf_recall'] = user_recall_items_dict\n",
    "pickle.dump(user_multi_recall_dict['itemcf_sim_itemcf_recall'], open(save_path + 'itemcf_recall_dict.pkl', 'wb'))\n",
    "\n",
    "if metric_recall:\n",
    "    # 召回效果评估\n",
    "    metrics_recall(user_multi_recall_dict['itemcf_sim_itemcf_recall'], trn_last_click_df, topk=recall_item_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "18f6b584-0869-452d-bc20-5549da429933",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(96877, 9.499786394735093),\n",
       " (159195, 6.835862992270029),\n",
       " (352979, 4.741662088818527),\n",
       " (211941, 3.948345356293222),\n",
       " (156625, 3.5535800212752804),\n",
       " (235804, 2.590151565850594),\n",
       " (36394, 2.2613890187022143),\n",
       " (285342, 2.2436125473730093),\n",
       " (124228, 2.0351748820164164),\n",
       " (284547, 1.4277951020384299)]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_multi_recall_dict['itemcf_sim_itemcf_recall'][1863]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ffa6a017-8f2e-4a31-8e99-84276fc0abab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>click_article_id</th>\n",
       "      <th>click_timestamp</th>\n",
       "      <th>click_environment</th>\n",
       "      <th>click_deviceGroup</th>\n",
       "      <th>click_os</th>\n",
       "      <th>click_country</th>\n",
       "      <th>click_region</th>\n",
       "      <th>click_referrer_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1096658</th>\n",
       "      <td>1863</td>\n",
       "      <td>70429</td>\n",
       "      <td>0.987307</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096659</th>\n",
       "      <td>1863</td>\n",
       "      <td>96877</td>\n",
       "      <td>0.987333</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id  click_article_id  click_timestamp  click_environment  \\\n",
       "1096658     1863             70429         0.987307                  4   \n",
       "1096659     1863             96877         0.987333                  4   \n",
       "\n",
       "         click_deviceGroup  click_os  click_country  click_region  \\\n",
       "1096658                  3         2              1            26   \n",
       "1096659                  3         2              1            26   \n",
       "\n",
       "         click_referrer_type  \n",
       "1096658                    1  \n",
       "1096659                    1  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_click_df[all_click_df.user_id == 1863]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcaea56a-ab37-449e-9e53-1c979c5db6fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3144fbec",
   "metadata": {},
   "source": [
    "## embedding sim 召回"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd605fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这里是为了召回评估，所以提取最后一次点击\n",
    "if metric_recall:\n",
    "    trn_hist_click_df, trn_last_click_df = get_hist_and_last_click(all_click_df)\n",
    "else:\n",
    "    trn_hist_click_df = all_click_df\n",
    "\n",
    "user_recall_items_dict = collections.defaultdict(dict)\n",
    "user_item_time_dict = get_user_item_time(trn_hist_click_df)\n",
    "i2i_sim = pickle.load(open(save_path + 'emb_i2i_sim.pkl','rb'))\n",
    "\n",
    "sim_item_topk = 20\n",
    "recall_item_num = 10\n",
    "\n",
    "item_topk_click = get_item_topk_click(trn_hist_click_df, k=50)\n",
    "\n",
    "for user in tqdm(trn_hist_click_df['user_id'].unique()):\n",
    "    user_recall_items_dict[user] = item_based_recommend(user, user_item_time_dict, i2i_sim, sim_item_topk, \n",
    "                                                        recall_item_num, item_topk_click, item_created_time_dict, emb_i2i_sim)\n",
    "    \n",
    "user_multi_recall_dict['embedding_sim_item_recall'] = user_recall_items_dict\n",
    "pickle.dump(user_multi_recall_dict['embedding_sim_item_recall'], open(save_path + 'embedding_sim_item_recall.pkl', 'wb'))\n",
    "\n",
    "if metric_recall:\n",
    "    # 召回效果评估\n",
    "    metrics_recall(user_multi_recall_dict['embedding_sim_item_recall'], trn_last_click_df, topk=recall_item_num)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1a279d",
   "metadata": {},
   "source": [
    "## userCF召回\n",
    "基于用户协同过滤，核心思想是给用户推荐与其相似的用户历史点击文章，因为这里涉及到了相似用户的历史文章，这里仍然可以加上一些关联规则来给用户可能点击的文章进行加权，这里使用的关联规则主要是考虑相似用户的历史点击文章与被推荐用户历史点击商品的关系权重，而这里的关系就可以直接借鉴基于物品的协同过滤相似的做法，只不过这里是对被推荐物品关系的一个累加的过程，下面是使用的一些关系权重，及相关的代码：\n",
    "\n",
    "1. 计算被推荐用户历史点击文章与相似用户历史点击文章的相似度，文章创建时间差，相对位置的总和，作为各自的权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd92bb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基于用户的召回 u2u2i\n",
    "def user_based_recommend(user_id, user_item_time_dict, u2u_sim, sim_user_topk, recall_item_num, \n",
    "                         item_topk_click, item_created_time_dict, emb_i2i_sim):\n",
    "    \"\"\"\n",
    "        基于文章协同过滤的召回\n",
    "        :param user_id: 用户id\n",
    "        :param user_item_time_dict: 字典, 根据点击时间获取用户的点击文章序列   {user1: {item1: time1, item2: time2..}...}\n",
    "        :param u2u_sim: 字典，文章相似性矩阵\n",
    "        :param sim_user_topk: 整数， 选择与当前用户最相似的前k个用户\n",
    "        :param recall_item_num: 整数， 最后的召回文章数量\n",
    "        :param item_topk_click: 列表，点击次数最多的文章列表，用户召回补全\n",
    "        :param item_created_time_dict: 文章创建时间列表\n",
    "        :param emb_i2i_sim: 字典基于内容embedding算的文章相似矩阵\n",
    "        \n",
    "        return: 召回的文章列表 {item1:score1, item2: score2...}\n",
    "    \"\"\"\n",
    "    # 历史交互\n",
    "    user_item_time_list = user_item_time_dict[user_id]    # {item1: time1, item2: time2...}\n",
    "    user_hist_items = set([i for i, t in user_item_time_list])   # 存在一个用户与某篇文章的多次交互， 这里得去重\n",
    "    \n",
    "    items_rank = {}\n",
    "    for sim_u, wuv in sorted(u2u_sim[user_id].items(), key=lambda x: x[1], reverse=True)[:sim_user_topk]:\n",
    "        for i, click_time in user_item_time_dict[sim_u]:\n",
    "            if i in user_hist_items:\n",
    "                continue\n",
    "            items_rank.setdefault(i, 0)\n",
    "            \n",
    "            loc_weight = 1.0\n",
    "            content_weight = 1.0\n",
    "            created_time_weight = 1.0\n",
    "            \n",
    "            # 当前文章与该用户看的历史文章进行一个权重交互\n",
    "            for loc, (j, click_time) in enumerate(user_item_time_list):\n",
    "                # 点击时的相对位置权重\n",
    "                loc_weight += 0.9 ** (len(user_item_time_list) - loc)\n",
    "                # 内容相似性权重\n",
    "                if emb_i2i_sim.get(i, {}).get(j, None) is not None:\n",
    "                    content_weight += emb_i2i_sim[i][j]\n",
    "                if emb_i2i_sim.get(j, {}).get(i, None) is not None:\n",
    "                    content_weight += emb_i2i_sim[j][i]\n",
    "                \n",
    "                # 创建时间差权重\n",
    "                created_time_weight += np.exp(0.8 * np.abs(item_created_time_dict[i] - item_created_time_dict[j]))\n",
    "                \n",
    "            items_rank[i] += loc_weight * content_weight * created_time_weight * wuv\n",
    "        \n",
    "    # 热度补全\n",
    "    if len(items_rank) < recall_item_num:\n",
    "        for i, item in enumerate(item_topk_click):\n",
    "            if item in items_rank.items(): # 填充的item应该不在原来的列表中\n",
    "                continue\n",
    "            items_rank[item] = - i - 100 # 随便给个复数就行\n",
    "            if len(items_rank) == recall_item_num:\n",
    "                break\n",
    "        \n",
    "    items_rank = sorted(items_rank.items(), key=lambda x: x[1], reverse=True)[:recall_item_num]    \n",
    "    \n",
    "    return items_rank\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ecf451d",
   "metadata": {},
   "source": [
    "## userCF sim召回"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d7942b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这里是为了召回评估，所以提取最后一次点击\n",
    "# 由于usercf中计算user之间的相似度的过程太费内存了，全量数据这里就没有跑，跑了一个采样之后的数据\n",
    "if metric_recall:\n",
    "    trn_hist_click_df, trn_last_click_df = get_hist_and_last_click(all_click_df)\n",
    "else:\n",
    "    trn_hist_click_df = all_click_df\n",
    "    \n",
    "user_recall_items_dict = collections.defaultdict(dict)\n",
    "user_item_time_dict = get_user_item_time(trn_hist_click_df)\n",
    "\n",
    "u2u_sim = pickle.load(open(save_path + 'usercf_u2u_sim.pkl', 'rb'))\n",
    "\n",
    "sim_user_topk = 20\n",
    "recall_item_num = 10\n",
    "item_topk_click = get_item_topk_click(trn_hist_click_df, k=50)\n",
    "\n",
    "for user in tqdm(trn_hist_click_df['user_id'].unique()):\n",
    "    user_recall_items_dict[user] = user_based_recommend(user, user_item_time_dict, u2u_sim, sim_user_topk, \\\n",
    "                                                        recall_item_num, item_topk_click, item_created_time_dict, emb_i2i_sim)    \n",
    "\n",
    "pickle.dump(user_recall_items_dict, open(save_path + 'usercf_u2u2i_recall.pkl', 'wb'))\n",
    "\n",
    "if metric_recall:\n",
    "    # 召回效果评估\n",
    "    metrics_recall(user_recall_items_dict, trn_last_click_df, topk=recall_item_num)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abec898c",
   "metadata": {},
   "source": [
    "## user embedding sim召回\n",
    "\n",
    "虽然没有直接跑usercf的计算用户之间的相似度，为了验证上述基于用户的协同过滤的代码，下面使用了YoutubeDNN过程中产生的user embedding来进行向量检索每个user最相似的topk个user，在使用这里得到的u2u的相似性矩阵，使用usercf进行召回，具体代码如下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db731f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用Embedding的方式获取u2u的相似性矩阵\n",
    "# topk指的是每个user, faiss搜索后返回最相似的topk个user\n",
    "def u2u_embdding_sim(click_df, user_emb_dict, save_path, topk):\n",
    "    \n",
    "    user_list = []\n",
    "    user_emb_list = []\n",
    "    for user_id, user_emb in user_emb_dict.items():\n",
    "        user_list.append(user_id)\n",
    "        user_emb_list.append(user_emb)\n",
    "        \n",
    "    user_index_2_rawid_dict = {k: v for k, v in zip(range(len(user_list)), user_list)}    \n",
    "    \n",
    "    user_emb_np = np.array(user_emb_list, dtype=np.float32)\n",
    "    \n",
    "    # 建立faiss索引\n",
    "    user_index = faiss.IndexFlatIP(user_emb_np.shape[1])\n",
    "    user_index.add(user_emb_np)\n",
    "    # 相似度查询，给每个索引位置上的向量返回topk个item以及相似度\n",
    "    sim, idx = user_index.search(user_emb_np, topk) # 返回的是列表\n",
    "   \n",
    "    # 将向量检索的结果保存成原始id的对应关系\n",
    "    user_sim_dict = collections.defaultdict(dict)\n",
    "    for target_idx, sim_value_list, rele_idx_list in tqdm(zip(range(len(user_emb_np)), sim, idx)):\n",
    "        target_raw_id = user_index_2_rawid_dict[target_idx]\n",
    "        # 从1开始是为了去掉商品本身, 所以最终获得的相似商品只有topk-1\n",
    "        for rele_idx, sim_value in zip(rele_idx_list[1:], sim_value_list[1:]): \n",
    "            rele_raw_id = user_index_2_rawid_dict[rele_idx]\n",
    "            user_sim_dict[target_raw_id][rele_raw_id] = user_sim_dict.get(target_raw_id, {}).get(rele_raw_id, 0) + sim_value\n",
    "    \n",
    "    # 保存i2i相似度矩阵\n",
    "    pickle.dump(user_sim_dict, open(save_path + 'youtube_u2u_sim.pkl', 'wb'))   \n",
    "    return user_sim_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d952713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取YoutubeDNN过程中产生的user embedding, 然后使用faiss计算用户之间的相似度\n",
    "# 这里需要注意，这里得到的user embedding其实并不是很好，因为YoutubeDNN中使用的是用户点击序列来训练的user embedding,\n",
    "# 如果序列普遍都比较短的话，其实效果并不是很好\n",
    "user_emb_dict = pickle.load(open(save_path + 'user_youtube_emb.pkl', 'rb'))\n",
    "u2u_sim = u2u_embdding_sim(all_click_df, user_emb_dict, save_path, topk=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506a7178",
   "metadata": {},
   "source": [
    "通过YoutubeDNN得到的user_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd063b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用召回评估函数验证当前召回方式的效果\n",
    "if metric_recall:\n",
    "    trn_hist_click_df, trn_last_click_df = get_hist_and_last_click(all_click_df)\n",
    "else:\n",
    "    trn_hist_click_df = all_click_df\n",
    "\n",
    "user_recall_items_dict = collections.defaultdict(dict)\n",
    "user_item_time_dict = get_user_item_time(trn_hist_click_df)\n",
    "u2u_sim = pickle.load(open(save_path + 'youtube_u2u_sim.pkl', 'rb'))\n",
    "\n",
    "sim_user_topk = 20\n",
    "recall_item_num = 10\n",
    "\n",
    "item_topk_click = get_item_topk_click(trn_hist_click_df, k=50)\n",
    "for user in tqdm(trn_hist_click_df['user_id'].unique()):\n",
    "    user_recall_items_dict[user] = user_based_recommend(user, user_item_time_dict, u2u_sim, sim_user_topk, \\\n",
    "                                                        recall_item_num, item_topk_click, item_created_time_dict, emb_i2i_sim)\n",
    "    \n",
    "user_multi_recall_dict['youtubednn_usercf_recall'] = user_recall_items_dict\n",
    "pickle.dump(user_multi_recall_dict['youtubednn_usercf_recall'], open(save_path + 'youtubednn_usercf_recall.pkl', 'wb'))\n",
    "\n",
    "if metric_recall:\n",
    "    # 召回效果评估\n",
    "    metrics_recall(user_multi_recall_dict['youtubednn_usercf_recall'], trn_last_click_df, topk=recall_item_num)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1e245a",
   "metadata": {},
   "source": [
    "# 冷启动问题\n",
    "冷启动问题可以分成三类：文章冷启动，用户冷启动，系统冷启动。\n",
    "\n",
    "- 文章冷启动：对于一个平台系统新加入的文章，该文章没有任何的交互记录，如何推荐给用户的问题。(对于我们场景可以认为是，日志数据中没有出现过的文章都可以认为是冷启动的文章)\n",
    "- 用户冷启动：对于一个平台系统新来的用户，该用户还没有文章的交互信息，如何给该用户进行推荐。(对于我们场景就是，测试集中的用户是否在测试集对应的log数据中出现过，如果没有出现过，那么可以认为该用户是冷启动用户。但是有时候并没有这么严格，我们也可以自己设定某些指标来判别哪些用户是冷启动用户，比如通过使用时长，点击率，留存率等等)\n",
    "- 系统冷启动：就是对于一个平台刚上线，还没有任何的相关历史数据，此时就是系统冷启动，其实也就是前面两种的一个综合。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ee0552",
   "metadata": {},
   "source": [
    "当前场景下冷启动问题的分析：\n",
    "\n",
    "对当前的数据进行分析会发现，日志中所有出现过的点击文章只有3w多个，而整个文章库中却有30多万，那么测试集中的用户最后一次点击是否会点击没有出现在日志中的文章呢？如果存在这种情况，说明用户点击的文章之前没有任何的交互信息，这也就是我们所说的文章冷启动。通过数据分析还可以发现，测试集用户只有一次点击的数据占得比例还不少，其实仅仅通过用户的一次点击就给用户推荐文章使用模型的方式也是比较难的，这里其实也可以考虑用户冷启动的问题，但是这里只给出物品冷启动的一些解决方案及代码，关于用户冷启动的话提一些可行性的做法。\n",
    "\n",
    "1. 文章冷启动(没有冷启动的探索问题)\n",
    "其实我们这里不是为了做文章的冷启动而做冷启动，而是猜测用户可能会点击一些没有在log数据中出现的文章，我们要做的就是如何从将近27万的文章中选择一些文章作为用户冷启动的文章，这里其实也可以看成是一种召回策略，我们这里就采用简单的比较好理解的基于规则的召回策略来获取用户可能点击的未出现在log数据中的文章。 现在的问题变成了：如何给每个用户考虑从27万个商品中获取一小部分商品？随机选一些可能是一种方案。下面给出一些参考的方案。\n",
    "    - 首先基于Embedding召回一部分与用户历史相似的文章\n",
    "    - 从基于Embedding召回的文章中通过一些规则过滤掉一些文章，使得留下的文章用户更可能点击。我们这里的规则，可以是，留下那些与用户历史点击文章主题相同的文章，或者字数相差不大的文章。并且留下的文章尽量是与测试集用户最后一次点击时间更接近的文章，或者是当天的文章也行。\n",
    "2. 用户冷启动\n",
    "这里对测试集中的用户点击数据进行分析会发现，测试集中有百分之20的用户只有一次点击，那么这些点击特别少的用户的召回是不是可以单独做一些策略上的补充呢？或者是在排序后直接基于规则加上一些文章呢？这些都可以去尝试，这里没有提供具体的做法。\n",
    "\n",
    "注意：\n",
    "\n",
    "这里看似和基于embedding计算的item之间相似度然后做itemcf是一致的，但是现在我们的目的不一样，我们这里的目的是找到相似的向量，并且还没有出现在log日志中的商品，再加上一些其他的冷启动的策略，这里需要找回的数量会偏多一点，不然被筛选完之后可能都没有文章了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db6fe70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 先进行itemcf召回，这里不需要做召回评估，这里只是一种策略\n",
    "trn_hist_click_df = all_click_df\n",
    "\n",
    "user_recall_items_dict = collections.defaultdict(dict)\n",
    "user_item_time_dict = get_user_item_time(trn_hist_click_df)\n",
    "i2i_sim = pickle.load(open(save_path + 'emb_i2i_sim.pkl','rb'))\n",
    "\n",
    "sim_item_topk = 150\n",
    "recall_item_num = 100 # 稍微召回多一点文章，便于后续的规则筛选\n",
    "\n",
    "item_topk_click = get_item_topk_click(trn_hist_click_df, k=50)\n",
    "for user in tqdm(trn_hist_click_df['user_id'].unique()):\n",
    "    user_recall_items_dict[user] = item_based_recommend(user, user_item_time_dict, i2i_sim, sim_item_topk, \n",
    "                                                        recall_item_num, item_topk_click,item_created_time_dict, emb_i2i_sim)\n",
    "pickle.dump(user_recall_items_dict, open(save_path + 'cold_start_items_raw_dict.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffbc647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基于规则进行文章过滤\n",
    "# 保留文章主题与用户历史浏览主题相似的文章\n",
    "# 保留文章字数与用户历史浏览文章字数相差不大的文章\n",
    "# 保留最后一次点击当天的文章\n",
    "# 按照相似度返回最终的结果\n",
    "\n",
    "def get_click_article_ids_set(all_click_df):\n",
    "    return set(all_click_df.click_article_id.values)\n",
    "\n",
    "def cold_start_items(user_recall_items_dict, user_hist_item_typs_dict, user_hist_item_words_dict, \\\n",
    "                     user_last_item_created_time_dict, item_type_dict, item_words_dict, \n",
    "                     item_created_time_dict, click_article_ids_set, recall_item_num):\n",
    "    \"\"\"\n",
    "        冷启动的情况下召回一些文章\n",
    "        :param user_recall_items_dict: 基于内容embedding相似性召回来的很多文章， 字典， {user1: [item1, item2, ..], }\n",
    "        :param user_hist_item_typs_dict: 字典， 用户点击的文章的主题映射\n",
    "        :param user_hist_item_words_dict: 字典， 用户点击的历史文章的字数映射\n",
    "        :param user_last_item_created_time_idct: 字典，用户点击的历史文章创建时间映射\n",
    "        :param item_tpye_idct: 字典，文章主题映射\n",
    "        :param item_words_dict: 字典，文章字数映射\n",
    "        :param item_created_time_dict: 字典， 文章创建时间映射\n",
    "        :param click_article_ids_set: 集合，用户点击过得文章, 也就是日志里面出现过的文章\n",
    "        :param recall_item_num: 召回文章的数量， 这个指的是没有出现在日志里面的文章数量\n",
    "    \"\"\"\n",
    "    \n",
    "    cold_start_user_items_dict = {}\n",
    "    for user, item_list in tqdm(user_recall_items_dict.items()):\n",
    "        cold_start_user_items_dict.setdefault(user, [])\n",
    "        for item, score in item_list:\n",
    "            # 获取历史文章信息\n",
    "            hist_item_type_set = user_hist_item_typs_dict[user]\n",
    "            hist_mean_words = user_hist_item_words_dict[user]\n",
    "            hist_last_item_created_time = user_last_item_created_time_dict[user]\n",
    "            hist_last_item_created_time = datetime.fromtimestamp(hist_last_item_created_time)\n",
    "            \n",
    "            # 获取当前召回文章的信息\n",
    "            curr_item_type = item_type_dict[item]\n",
    "            curr_item_words = item_words_dict[item]\n",
    "            curr_item_created_time = item_created_time_dict[item]\n",
    "            curr_item_created_time = datetime.fromtimestamp(curr_item_created_time)\n",
    "\n",
    "            # 首先，文章不能出现在用户的历史点击中， 然后根据文章主题，文章单词数，文章创建时间进行筛选\n",
    "            if curr_item_type not in hist_item_type_set or \\\n",
    "                item in click_article_ids_set or \\\n",
    "                abs(curr_item_words - hist_mean_words) > 200 or \\\n",
    "                abs((curr_item_created_time - hist_last_item_created_time).days) > 90: \n",
    "                continue\n",
    "                \n",
    "            cold_start_user_items_dict[user].append((item, score))      # {user1: [(item1, score1), (item2, score2)..]...}\n",
    "    \n",
    "    # 需要控制一下冷启动召回的数量\n",
    "    cold_start_user_items_dict = {k: sorted(v, key=lambda x:x[1], reverse=True)[:recall_item_num] \\\n",
    "                                  for k, v in cold_start_user_items_dict.items()}\n",
    "    \n",
    "    pickle.dump(cold_start_user_items_dict, open(save_path + 'cold_start_user_items_dict.pkl', 'wb'))\n",
    "    \n",
    "    return cold_start_user_items_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1e88d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_click_df_ = all_click_df.copy()\n",
    "all_click_df_ = all_click_df_.merge(item_info_df, how='left', on='click_article_id')\n",
    "user_hist_item_typs_dict, user_hist_item_ids_dict, user_hist_item_words_dict, user_last_item_created_time_dict = get_user_hist_item_info_dict(all_click_df_)\n",
    "click_article_ids_set = get_click_article_ids_set(all_click_df)\n",
    "# 需要注意的是\n",
    "# 这里使用了很多规则来筛选冷启动的文章，所以前面再召回的阶段就应该尽可能的多召回一些文章，否则很容易被删掉\n",
    "cold_start_user_items_dict = cold_start_items(user_recall_items_dict, user_hist_item_typs_dict, user_hist_item_words_dict, \\\n",
    "                                              user_last_item_created_time_dict, item_type_dict, item_words_dict, \\\n",
    "                                              item_created_time_dict, click_article_ids_set, recall_item_num)\n",
    "\n",
    "user_multi_recall_dict['cold_start_recall'] = cold_start_user_items_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a996c2c4",
   "metadata": {},
   "source": [
    "# 多路召回合并\n",
    "多路召回合并就是将前面所有的召回策略得到的用户文章列表合并起来，下面是对前面所有召回结果的汇总\n",
    "\n",
    "1. 基于itemcf计算的item之间的相似度sim进行的召回\n",
    "2. 基于embedding搜索得到的item之间的相似度进行的召回\n",
    "3. YoutubeDNN召回\n",
    "4. YoutubeDNN得到的user之间的相似度进行的召回\n",
    "5. 基于冷启动策略的召回\n",
    "\n",
    "注意：\n",
    "在做召回评估的时候就会发现有些召回的效果不错有些召回的效果很差，所以对每一路召回的结果，我们可以认为的定义一些权重，来做最终的相似度融合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f84ca1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_recall_results(user_multi_recall_dict, weight_dict=None, topk=25):\n",
    "    final_recall_items_dict = {}\n",
    "    \n",
    "    # 对每一种召回结果按照用户进行归一化，方便后面多种召回结果，相同用户的物品之间权重相加\n",
    "    def norm_user_recall_items_sim(sorted_item_list):\n",
    "        # 如果冷启动中没有文章或者只有一篇文章，直接返回，出现这种情况的原因可能是冷启动召回的文章数量太少了，\n",
    "        # 基于规则筛选之后就没有文章了, 这里还可以做一些其他的策略性的筛选\n",
    "        if len(sorted_item_list) < 2:\n",
    "            return sorted_item_list\n",
    "        \n",
    "        min_sim = sorted_item_list[-1][1]\n",
    "        max_sim = sorted_item_list[0][1]\n",
    "        \n",
    "        norm_sorted_item_list = []\n",
    "        for item, score in sorted_item_list:\n",
    "            if max_sim > 0:\n",
    "                norm_score = 1.0 * (score - min_sim) / (max_sim - min_sim) if max_sim > min_sim else 1.0\n",
    "            else:\n",
    "                norm_score = 0.0\n",
    "            norm_sorted_item_list.append((item, norm_score))\n",
    "            \n",
    "        return norm_sorted_item_list\n",
    "    \n",
    "    print('多路召回合并...')\n",
    "    for method, user_recall_items in tqdm(user_multi_recall_dict.items()):\n",
    "        print(method + '...')\n",
    "        # 在计算最终召回结果的时候，也可以为每一种召回结果设置一个权重\n",
    "        if weight_dict == None:\n",
    "            recall_method_weight = 1\n",
    "        else:\n",
    "            recall_method_weight = weight_dict[method]\n",
    "        \n",
    "        for user_id, sorted_item_list in user_recall_items.items(): # 进行归一化\n",
    "            user_recall_items[user_id] = norm_user_recall_items_sim(sorted_item_list)\n",
    "        \n",
    "        for user_id, sorted_item_list in user_recall_items.items():\n",
    "            # print('user_id')\n",
    "            final_recall_items_dict.setdefault(user_id, {})\n",
    "            for item, score in sorted_item_list:\n",
    "                final_recall_items_dict[user_id].setdefault(item, 0)\n",
    "                final_recall_items_dict[user_id][item] += recall_method_weight * score  \n",
    "    \n",
    "    final_recall_items_dict_rank = {}\n",
    "    # 多路召回时也可以控制最终的召回数量\n",
    "    for user, recall_item_dict in final_recall_items_dict.items():\n",
    "        final_recall_items_dict_rank[user] = sorted(recall_item_dict.items(), key=lambda x: x[1], reverse=True)[:topk]\n",
    "\n",
    "    # 将多路召回后的最终结果字典保存到本地\n",
    "    pickle.dump(final_recall_items_dict, open(os.path.join(save_path, 'final_recall_items_dict.pkl'),'wb'))\n",
    "\n",
    "    return final_recall_items_dict_rank\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e56e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这里直接对多路召回的权重给了一个相同的值，其实可以根据前面召回的情况来调整参数的值\n",
    "weight_dict = {'itemcf_sim_itemcf_recall': 1.0,\n",
    "               'embedding_sim_item_recall': 1.0,\n",
    "               'youtubednn_recall': 1.0,\n",
    "               'youtubednn_usercf_recall': 1.0, \n",
    "               'cold_start_recall': 1.0}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7865463f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最终合并之后每个用户召回150个商品进行排序\n",
    "final_recall_items_dict_rank = combine_recall_results(user_multi_recall_dict, weight_dict, topk=150)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb460b53",
   "metadata": {},
   "source": [
    "# 总结\n",
    "上述实现了如下召回策略：\n",
    "\n",
    "- 基于关联规则的itemcf\n",
    "- 基于关联规则的usercf\n",
    "- youtubednn召回\n",
    "- 冷启动召回\n",
    "\n",
    "对于上述实现的召回策略其实都不是最优的结果，我们只是做了个简单的尝试，其中还有很多地方可以优化，包括已经实现的这些召回策略的参数或者新加一些，修改一些关联规则都可以。当然还可以尝试更多的召回策略，比如对新闻进行热度召回等等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43133074",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
